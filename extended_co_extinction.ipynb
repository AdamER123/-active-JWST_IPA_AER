{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cea008b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A code to analyze image cubes from the JWST nirspec ifu - examples here are done with CO\n",
    "#By Adam E. Rubinstein\n",
    "\n",
    "# load important packages\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d #UnivariateSpline\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from astropy.io import fits #, ascii\n",
    "from astropy import units as u\n",
    "import pandas as pd\n",
    "from spectral_cube import SpectralCube"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0cc6d5ad",
   "metadata": {},
   "source": [
    "# Read in CO data\n",
    "\n",
    "Also can show line/continuum ratio as an optional figure idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f67a81ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing fits images of CO line emission to be saved...\n",
    "#first define some lists to loop over for the different CO line series\n",
    "# protostar_list = ['IRAS16253', 'B335', 'HOPS153', 'HOPS370', 'IRAS20126']\n",
    "# protostar_names = ['IRAS 16253', 'B335', 'HOPS 153', 'HOPS 370', 'IRAS 20126'] #just to add some spaces\n",
    "v_list = ['1*'] #, '2*', '3*']\n",
    "j_list = ['R*', 'P*']\n",
    "pc_to_cm = 3.086e18\n",
    "dist_list = pc_to_cm*np.array([150, 165, 390, 390, 1.55e3]) #pc: from Ortiz-Leon 2018, Watson 2020, Tobin+2020a, Tobin+2020a, Reid+2019\n",
    "protostars = ['IRAS16253', 'B335', 'HOPS153', 'HOPS370', 'IRAS20126']\n",
    "\n",
    "#some lists related to correcting for ices\n",
    "transmission_folder = '../Ices/'\n",
    "transmission_file_end = '_NIRspec_cube_pspline_asls_transmission.fits' \n",
    "offset_list = [1.85e-3, 2e-3, 1.1e-3, 1.1e-3, 2.25e-3] #experimental, from cube fitting, needed to fix wavelengths we're using here\n",
    "\n",
    "#a function to generate lists of co line intensity maps for our protostars\n",
    "def co_data_output(protostar_str, v_str, j_str):\n",
    "    #read in some protostellar images for each protostar\n",
    "    co_file_list = sorted(glob('../Line_Images/'+ protostar_str + '*_CO*v=' + v_str + j_str + '.fits'), key=lambda x: int(x.split('_')[-2][-2:]), reverse=True) #change the wildcard '*' here!; note we need the key to order images by number...\n",
    "\n",
    "    #extract useful values and labels from file names in case of saving...\n",
    "    #just using an example star to figure out general process (whatever is first), then loop later\n",
    "    co_j =  [i.split('_')[-2][-2:] for i in co_file_list] \n",
    "    co_wavelengths = np.array([float(i.split('_')[-1][:-5]) for i in co_file_list])\n",
    "\n",
    "    #setting up and correcting units\n",
    "    hdul_co = [fits.open(j) for j in co_file_list]     #extract hdu files from paths\n",
    "    sr_conversion = np.abs(hdul_co[0][0].header['CDELT1'] * hdul_co[0][0].header['CDELT2'] / (180. / np.pi)**2.0) #square degrees to steradians, should be consistent throughout all images (?)\n",
    "    # mega_conversion = 1e6 #can swap out with Jy conversion to preferred units...\n",
    "    co_data = [j[0].data*sr_conversion for j in hdul_co]     #extracting data for each hdu, converting units\n",
    "\n",
    "    #reading in transmission file needed to slightly correct data\n",
    "    protostar_ind = protostars.index(protostar_str) #if you'd like to do this by indexing\n",
    "    hdul_transmission = fits.open(transmission_folder + protostar_str + transmission_file_end) #read in hdu\n",
    "    transmission_cube = SpectralCube.read(hdul_transmission[0]) #accessing the cube for data  \n",
    "    transmission_data = np.array(transmission_cube._data, dtype=np.float64) #open transmission slices\n",
    "    co_header = transmission_cube[0].header #we need headers for later, but we can only take one slice (doesn't work if NAXIS > 2: https://github.com/aplpy/aplpy/issues/449)\n",
    "    jwst_wavelengths = transmission_cube.spectral_axis.value/1e-6 + offset_list[protostar_ind]\n",
    "    transmit_splined = interp1d(jwst_wavelengths, transmission_data, axis=0) #transmission data\n",
    "\n",
    "    #correcting for ices by dividing them out as a transmission filter centered at the peak wavelength of each line\n",
    "    # wave_cutoff_idx = np.where((co_wavelengths > 4.52)*(co_wavelengths < 4.96))[0]     #first spline the transmission curve, masking it where we want to apply it (wavelengths between 4.52 and 4.96)\n",
    "    # co_data_corrected = [co_data[j] / transmit_splined_list[protostar_ind](co_wavelengths[j]) for j in wave_cutoff_idx] #then apply transmission curve\n",
    "    co_data_corrected = []\n",
    "    for i in range(len(co_wavelengths)): #making a brute force loop and condition since the mask wasn't working right\n",
    "        if co_wavelengths[i] > 4.52 and co_wavelengths[i] < 4.96:\n",
    "            co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
    "        else:\n",
    "            co_data_corrected.append(co_data[i])\n",
    "\n",
    "    #applying smoothing or SNR cut (optional)\n",
    "    # jwst_err_cube = hdul['ERR'].data #not using spectral cube here\n",
    "    # err_flux1 = np.array(jwst_err_cube[:, ind1, ind2], dtype=np.float64)\n",
    "    # flux1[ flux1/err_flux1 < 1] = 0\n",
    "    # print(type(flux1[0])) #checking if float64\n",
    "\n",
    "    return co_j, co_wavelengths, co_data, co_data_corrected, co_header, transmit_splined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54676c74",
   "metadata": {},
   "source": [
    "# Collect lab values\n",
    "Like Einstein coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b403bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in from line list for CO\n",
    "#done first so we can add it to our long table!\n",
    "# columns = A, sec-1\tE_u/k\tg_u\n",
    "table_path = '../Line list 2.1 for python.xlsx'\n",
    "column_names = ['Wv, microns', 'A, sec-1', 'E_u/k', 'g_u']\n",
    "co_lab_props = pd.read_excel(table_path, sheet_name='CO', usecols=column_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42d28c8c",
   "metadata": {},
   "source": [
    "# Compute extinction, tau across map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfd2caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optically thin case for foreground extinction\n",
    "from scipy.interpolate import CubicSpline\n",
    "\n",
    "#for de-extincting, you need the file below! It is taken from Bruce Draine's website for Rv = 5.5, to be interpolated\n",
    "#https://ui.adsabs.harvard.edu/abs/2001ApJ...548..296W/abstract\n",
    "#this is used for the cross sections Cext or kext, which can be used to compute tau or Av\n",
    "#extracting data\n",
    "# kext_dat = np.genfromtxt('kext_albedo_WD_MW_5.5A_30_D03_delimmod.txt', delimiter=' ', dtype=None, skip_header=80, usecols=range(0,5)) #reading in excel file of extinctions\n",
    "# kext_dat_ascend = sorted(kext_dat, key=lambda x:x[0]) #sorted in ascending order, from small to large lambda\n",
    "kext_dat_ascend = pd.read_excel('../extinc_kp5.0_rv_ncol.xlsx') #UPGRADE: klaus pontoppidan 5.0\n",
    "\n",
    "#extracting relevant data and interpolating\n",
    "lam_kext = kext_dat_ascend['lambda, microns'].values  # [i[0] for i in kext_dat_ascend]\n",
    "Cext_kext = kext_dat_ascend['extinction cross section, cm^2'].values # [i[4] for i in kext_dat_ascend] #cross section per H nucleon (?); change columns depending on file\n",
    "vs = CubicSpline(lam_kext, Cext_kext) #the all important interpolating function, note it comes from Cext on the table\n",
    "\n",
    "#function and global lambdaV for reference\n",
    "lambdaV = 0.547\n",
    "def extinc(co_r_wavelengths, co_p_wavelengths, co_r_p_ratio_list, co_A_ij_r, co_A_ij_p):\n",
    "    #computing intrinsic lab measured ratio\n",
    "    r_to_p_0 = co_A_ij_r/co_A_ij_p * co_p_wavelengths/co_r_wavelengths #from HITRAN\n",
    "    C_ext_co = vs(co_r_wavelengths) - vs(co_p_wavelengths) #needed to define \"Rv\" for our set of CO transitions\n",
    "    \n",
    "    #computing tau for each image, then taking image * exp(tau) to de-extinct, and saving\n",
    "    ''' \n",
    "    av = vs(lambdaV)/C_ext_co * 2.5 * np.log10(r_to_p_0 / i)\n",
    "    av_err = vs(lambdaV)/C_ext_co * 2.5 * r_to_p_0 / np.log(10.0) * co_err_r_p_ratio_list[i] / co_r_p_ratio_list[i]\n",
    "    '''\n",
    "    # co_red_list = 2.5 * np.log10(r_to_p_0 / co_r_p_ratio_list) #the reddening Rv / Av = E\n",
    "    # co_red_err_list = 2.5 * r_to_p_0 / np.log(10.0) * co_err_r_p_ratio_list / co_r_p_ratio_list #note that log(x) -> dx/x for uncertainty (e.g. https://openbooks.library.umass.edu/p132-lab-manual/chapter/uncertainty-for-natural-logarithms/)\n",
    "    # co_av_list = vs(lambdaV)/C_ext_co * co_red_list #visual extinction, Av\n",
    "    # co_av_err_list = vs(lambdaV)/C_ext_co * co_red_err_list\n",
    "\n",
    "    #now we are closer to full analysis, but first we need tau in the continuum to deextinct...\n",
    "    ''' \n",
    "    keep in mind we are doing a ratio of co values...this means we are doing a ratio of different tau ultimately...\n",
    "    deext ratio = (flux_co_r * exp(tau_r)) / (flux_co_p * exp(tau_p))\n",
    "    deext sum = (flux_co_r * exp(tau_r)) + (flux_co_p * exp(tau_p))\n",
    "    '''\n",
    "    tau_r_ext_list = vs(co_r_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
    "    tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
    "\n",
    "    #computing uncertainties in tau\n",
    "    # tau_r_err_list = vs(co_r_wavelengths[:,None,None]) / C_ext_co * r_to_p_0 * co_err_r_p_ratio_list /  co_r_p_ratio_list\n",
    "    # tau_p_err_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co * r_to_p_0 * co_err_r_p_ratio_list /  co_r_p_ratio_list\n",
    "\n",
    "\n",
    "    #we also want tau / sigma = Sigma = n L, a column density\n",
    "    column_density_r_list = tau_r_ext_list / vs(co_r_wavelengths[:,None,None])\n",
    "    column_density_p_list = tau_p_ext_list / vs(co_p_wavelengths[:,None,None])\n",
    "\n",
    "    return column_density_r_list, column_density_p_list, tau_r_ext_list, tau_p_ext_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd6d3bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in a list of spectral cubes to extract wcs headers...\n",
    "file_list = [glob('../' + i + '/*.fits')[0].replace('\\\\', '/') for i in protostars]\n",
    "hdul = [fits.open(filepath) for filepath in file_list]\n",
    "jwst_cube_list = [SpectralCube.read(hdu[1]) for hdu in hdul] #accessing the cube for data  \n",
    "jwst_wcs_list = [cube.wcs for cube in jwst_cube_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11f596a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: WCSWarning: WCS1 is missing card DATE-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card XPOSURE [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card TELAPSE [spectral_cube.wcs_utils]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card XPOSURE [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card TELAPSE [spectral_cube.wcs_utils]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\285379221.py:40: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_r_p_ratio_list = co_r_flux_sorted / co_p_flux_sorted #note if conversion done here\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\285379221.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_r_p_ratio_list = co_r_flux_sorted / co_p_flux_sorted #note if conversion done here\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:40: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_r_ext_list = vs(co_r_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:40: RuntimeWarning: invalid value encountered in log\n",
      "  tau_r_ext_list = vs(co_r_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: invalid value encountered in log\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:  CO_Extinction_Maps/IRAS16253_NIRspec_cube_CO_r_v1_extcol.fits\n",
      "Saved:  CO_Extinction_Maps/IRAS16253_NIRspec_cube_CO_p_v1_extcol.fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: WCSWarning: WCS1 is missing card DATE-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card XPOSURE [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card TELAPSE [spectral_cube.wcs_utils]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card XPOSURE [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card TELAPSE [spectral_cube.wcs_utils]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\285379221.py:40: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_r_p_ratio_list = co_r_flux_sorted / co_p_flux_sorted #note if conversion done here\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\285379221.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_r_p_ratio_list = co_r_flux_sorted / co_p_flux_sorted #note if conversion done here\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:40: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_r_ext_list = vs(co_r_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:40: RuntimeWarning: invalid value encountered in log\n",
      "  tau_r_ext_list = vs(co_r_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: invalid value encountered in log\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:  CO_Extinction_Maps/B335_NIRspec_cube_CO_r_v1_extcol.fits\n",
      "Saved:  CO_Extinction_Maps/B335_NIRspec_cube_CO_p_v1_extcol.fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: WCSWarning: WCS1 is missing card DATE-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card XPOSURE [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card TELAPSE [spectral_cube.wcs_utils]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card XPOSURE [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card TELAPSE [spectral_cube.wcs_utils]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\285379221.py:40: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_r_p_ratio_list = co_r_flux_sorted / co_p_flux_sorted #note if conversion done here\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\285379221.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_r_p_ratio_list = co_r_flux_sorted / co_p_flux_sorted #note if conversion done here\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:40: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_r_ext_list = vs(co_r_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:40: RuntimeWarning: invalid value encountered in log\n",
      "  tau_r_ext_list = vs(co_r_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: invalid value encountered in log\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' 0' ' 1' ' 2' ' 3' ' 4' ' 5' ' 6' ' 7' ' 8' ' 9' '10' '11' '12' '13'\n",
      " '14' '15' '16' '17' '18' '19' '20' '21' '22' '23' '24' '25' '26' '27'\n",
      " '28' '29' '30' '31' '32' '33' '34' '35' '36' '37' '38' '39' '40' '41'\n",
      " '42' '43' '44' '45' '46' '47' '48' '49' '50']\n",
      "[' 2' ' 3' ' 4' ' 5' ' 6' ' 7' ' 8' ' 9' '10' '11' '12' '13' '14' '15'\n",
      " '16' '17' '18' '19' '20' '21' '22' '23' '24' '25' '26' '27' '28' '29'\n",
      " '30' '31' '32' '33' '34' '35' '36' '37' '38' '39' '40' '41' '42' '43'\n",
      " '44' '45' '46' '47' '48' '49' '50' '51' '52']\n",
      "Saved:  CO_Extinction_Maps/HOPS153_NIRspec_cube_CO_r_v1_extcol.fits\n",
      "Saved:  CO_Extinction_Maps/HOPS153_NIRspec_cube_CO_p_v1_extcol.fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: WCSWarning: WCS1 is missing card DATE-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card XPOSURE [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card TELAPSE [spectral_cube.wcs_utils]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card XPOSURE [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card TELAPSE [spectral_cube.wcs_utils]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\285379221.py:40: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_r_p_ratio_list = co_r_flux_sorted / co_p_flux_sorted #note if conversion done here\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\285379221.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_r_p_ratio_list = co_r_flux_sorted / co_p_flux_sorted #note if conversion done here\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:40: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_r_ext_list = vs(co_r_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:40: RuntimeWarning: invalid value encountered in log\n",
      "  tau_r_ext_list = vs(co_r_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: invalid value encountered in log\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:  CO_Extinction_Maps/HOPS370_NIRspec_cube_CO_r_v1_extcol.fits\n",
      "Saved:  CO_Extinction_Maps/HOPS370_NIRspec_cube_CO_p_v1_extcol.fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: WCSWarning: WCS1 is missing card DATE-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card XPOSURE [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card TELAPSE [spectral_cube.wcs_utils]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-BEG [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card DATE-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card MJD-END [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card XPOSURE [spectral_cube.wcs_utils]\n",
      "WARNING: WCSWarning: WCS1 is missing card TELAPSE [spectral_cube.wcs_utils]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\400570441.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_data_corrected.append(co_data[i] / transmit_splined(co_wavelengths[i]))\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\285379221.py:40: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  co_r_p_ratio_list = co_r_flux_sorted / co_p_flux_sorted #note if conversion done here\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\285379221.py:40: RuntimeWarning: invalid value encountered in true_divide\n",
      "  co_r_p_ratio_list = co_r_flux_sorted / co_p_flux_sorted #note if conversion done here\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:40: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_r_ext_list = vs(co_r_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:40: RuntimeWarning: invalid value encountered in log\n",
      "  tau_r_ext_list = vs(co_r_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_7880\\2372777484.py:41: RuntimeWarning: invalid value encountered in log\n",
      "  tau_p_ext_list = vs(co_p_wavelengths[:,None,None]) / C_ext_co[:,None,None] * np.log(r_to_p_0[:,None,None] / co_r_p_ratio_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:  CO_Extinction_Maps/IRAS20126_NIRspec_cube_CO_r_v1_extcol.fits\n",
      "Saved:  CO_Extinction_Maps/IRAS20126_NIRspec_cube_CO_p_v1_extcol.fits\n"
     ]
    }
   ],
   "source": [
    "from astropy.wcs import WCS\n",
    "\n",
    "#input values, such as wavelength resolution for our lookup tables\n",
    "wave_lookup_res = 0.000001\n",
    "protostar_idx = 0 #for use in tests\n",
    "avg_ext_arr = [] #empty list needed to be filled for each protostar\n",
    "avg_av_unc_arr = [] #empty list needed to be filled for each protostar\n",
    "# transmiss_threshold_list = [[0.64], [0.69, 0.69, 0.69], [0.64, 0.64], [0.84, 0.84, 0.84], [0.84, 0.84]]\n",
    "transmiss_threshold_list = [0.62, 0.6, 0.63, 0.7, 0.7]\n",
    "\n",
    "#loop thorugh protostars and compute a table of fluxes:\n",
    "for i in range(len(protostars)):\n",
    "    count = 0\n",
    "    co_av_list = []\n",
    "    av_masks = [] #empty list to be filled for each protostar\n",
    "\n",
    "    #loop through vibrational states (each axis)\n",
    "    for j in range(len(v_list)):\n",
    "        #loop through the rotational states to collect a set of data and usable values\n",
    "        #doing it by hand here since will only ever be two options\n",
    "        co_v_r_j, co_v_r_wavelengths, co_v_r_data, co_v_r_data_corrected, co_header, transmit_splined = co_data_output(protostars[i], v_list[j], j_list[0])\n",
    "        co_v_p_j, co_v_p_wavelengths, co_v_p_data, co_v_p_data_corrected, co_header, transmit_splined = co_data_output(protostars[i], v_list[j], j_list[1])\n",
    "\n",
    "        #only can do for j with v = 1-0...\n",
    "            #fix wavelengths and J\n",
    "        co_v_r_sorted = np.array(co_v_r_j[8:][::-1])\n",
    "        co_v_p_sorted = np.array(co_v_p_j[:-1][::-1])\n",
    "        co_r_wave_sorted = np.array(co_v_r_wavelengths[8:][::-1])\n",
    "        co_p_wave_sorted = np.array(co_v_p_wavelengths[:-1][::-1])\n",
    "        co_r_flux_sorted = np.array(co_v_r_data[8:][::-1])\n",
    "        co_p_flux_sorted = np.array(co_v_p_data[:-1][::-1])\n",
    "        # co_r_fluxerr_sorted = np.array(co_err_r_flux_list[8:][::-1])\n",
    "        # co_p_fluxerr_sorted = np.array(co_err_p_flux_list[:-1][::-1])\n",
    "\n",
    "        if i == 2:\n",
    "            print(co_v_r_sorted)\n",
    "            print(co_v_p_sorted)\n",
    "\n",
    "        #some useful ratios and propagated the ratio of uncertainties for later too\n",
    "        co_r_p_ratio_list = co_r_flux_sorted / co_p_flux_sorted #note if conversion done here\n",
    "        # co_err_r_p_ratio_list = co_r_p_ratio_list * np.sqrt( (co_r_fluxerr_sorted/co_r_flux_sorted)**2. + (co_p_fluxerr_sorted/co_p_flux_sorted)**2.) #note conversion done here\n",
    "\n",
    "            \n",
    "        #look up the co lab properties we need and split them into r and p branches for use in calculations\n",
    "        #column_names[0] is 'Wv, microns', the first column of the co lab properties\n",
    "        #wave_lookup_res is at the start of this code block and is about the minimum allowed\n",
    "        #r-branch\n",
    "        co_A_ij_r = [] #list of indices for use in looking up wavelengths and matching what we have to the lab properties\n",
    "        for k in range(len(co_r_wave_sorted)):\n",
    "            idx = (co_lab_props[column_names[0]] <= co_r_wave_sorted[k]+wave_lookup_res) & (co_lab_props[column_names[0]] > co_r_wave_sorted[k]-wave_lookup_res)\n",
    "            co_A_ij_r.append(co_lab_props[column_names[1]][idx].values[0]) #apply indices to and lookup in table of lab properties\n",
    "        co_A_ij_r = np.array(co_A_ij_r)\n",
    "\n",
    "        #p-branch\n",
    "        co_A_ij_p = [] #list of indices for use in looking up wavelengths and matching what we have to the lab properties\n",
    "        for k in range(len(co_p_wave_sorted)):\n",
    "            idx = (co_lab_props[column_names[0]] <= co_p_wave_sorted[k]+wave_lookup_res) & (co_lab_props[column_names[0]] > co_p_wave_sorted[k]-wave_lookup_res)\n",
    "            co_A_ij_p.append(co_lab_props[column_names[1]][idx].values[0]) #apply indices to and lookup in table of lab properties\n",
    "        co_A_ij_p = np.array(co_A_ij_p)\n",
    "\n",
    "        #determine extinction here!\n",
    "        # co_av_list, co_av_err_list, tau_r_ext_list, tau_p_ext_list, tau_r_err_list, tau_p_err_list = extinc(co_r_wave_sorted, co_p_wave_sorted, co_r_p_ratio_list, co_err_r_p_ratio_list, co_A_ij_r, co_A_ij_p)\n",
    "        column_density_r_list, column_density_p_list, tau_r_ext_list, tau_p_ext_list = extinc(co_r_wave_sorted, co_p_wave_sorted, co_r_p_ratio_list, co_A_ij_r, co_A_ij_p)        \n",
    "        avg_ext_arr.append(tau_r_ext_list)\n",
    "\n",
    "        #saving extinction as cube, not summed\n",
    "        # cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "        cube = SpectralCube(data=column_density_r_list, wcs=jwst_wcs_list[i])\n",
    "        # cube = cube.with_spectral_unit(u.um)\n",
    "        cube_savepath = 'CO_Extinction_Maps/'\n",
    "        cube_name = protostars[i] + '_NIRspec_cube_CO_r_v' + str(j+1) + '_extcol.fits'\n",
    "        cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "        print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "        #saving baseline as cube, not summed, with MJy/sr\n",
    "        # cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "        cube = SpectralCube(data=column_density_p_list, wcs=jwst_wcs_list[i])\n",
    "        # cube = cube.with_spectral_unit(u.um)\n",
    "        cube_savepath = 'CO_Extinction_Maps/'\n",
    "        cube_name = protostars[i] + '_NIRspec_cube_CO_p_v' + str(j+1) + '_extcol.fits'\n",
    "        cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "        print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "\n",
    "#     #now to make some example plots; we will pick one for later\n",
    "#     ### TRANSMISSION CURVE\n",
    "#     #for each protostar, we can now define an averaged transmission function in order to threshold our extinction values\n",
    "#     #must be done once for each vibrational state as well\n",
    "#     transmiss_p_sorted = np.array([transmit_splined(k) for k in co_p_wave_sorted])\n",
    "#     transmiss_r_sorted = np.array([transmit_splined(k) for k in co_r_wave_sorted])\n",
    "\n",
    "#     ### AV HISTOGRAM + TESTING TRANSMISSION PERCENTAGE THRESHOLD\n",
    "#     #need to filter out a given set of vibrational data here\n",
    "#     for k1,k2 in zip(transmiss_r_sorted, transmiss_p_sorted):\n",
    "#         if k1 > transmiss_threshold_list[i] and k2 > transmiss_threshold_list[i]:\n",
    "#             # print(k1, k2, co_av_list[count])\n",
    "#             av_masks.append(count)\n",
    "#         count += 1\n",
    "        \n",
    "    # #compile values\n",
    "    # av_arr = np.concatenate(av_arr)\n",
    "    # av_masks = np.array(av_masks)\n",
    "    # # print(av_masks)\n",
    "    # # print(av_arr[av_masks])    \n",
    "    \n",
    "    # #masking values\n",
    "    # av_pos_masked = av_arr[av_masks]\n",
    "    # av_pos_masked[av_pos_masked < 0] = np.nan\n",
    "    # av_pos_masked[av_pos_masked > 1000] = np.nan\n",
    "    # avg_av_filtered = np.nanmedian(av_pos_masked)\n",
    "    # avg_ext_arr.append(avg_av_filtered)\n",
    "    # avg_av_unc_arr.append(np.nanstd(av_pos_masked, ddof=1)/np.sqrt(len(av_pos_masked)))\n",
    "    # # print('Uncertainties: ', co_av_err_list)\n",
    "    # print('Removed Outliers: ', avg_av_filtered, 'High Transmission, still outliers: ', np.nanmedian(av_arr[av_masks]))\n",
    "    # print('StD of high transmission + outliers removed: ', np.nanstd(av_pos_masked, ddof=1)/np.sqrt(len(av_pos_masked)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4225ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "76ea0b5a44b5f043d6c4635159a3bee32cd62df1b18398bac551d6d1b233642a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
