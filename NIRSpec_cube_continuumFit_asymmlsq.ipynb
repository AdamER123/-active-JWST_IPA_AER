{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea008b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A code to fit continuum, pseudo-continuum, and/or baselines to image cubes from the JWST nirspec ifu\n",
    "#By Adam E. Rubinstein\n",
    "\n",
    "# load important packages\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d, UnivariateSpline\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "import pandas as pd\n",
    "from spectral_cube import SpectralCube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce3f23",
   "metadata": {},
   "source": [
    "Options forbaseline fitting\n",
    "\n",
    "Asymmetric least squares smoother: from spectrapepper: https://github.com/spectrapepper/spectrapepper/blob/main/spectrapepper/functions.py\n",
    "\n",
    "see function alsbaseline\n",
    "\n",
    "last parameters that worked: smooth_list = [10000, 0.1, 0.1, 1, 10, 10, 0.1, 1], p_list = [0.05, 0.01, 0.05, 0.005, 0.0005, 0.01, 0.0001]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae17db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a new fits file to be saved, maybe viewed in DS9\n",
    "# may need to modify the function for a particular image, but generally useful\n",
    "def fits_saver(array, wcs_header, name, save_path):\n",
    "    '''\n",
    "    array is a 2d array of data - could be from reprojecting one image onto another or from convolution...\n",
    "    wcs_header is a header containing the wcs coords of the image that we projected onto or of the orig image (if from the convolution)\n",
    "    name can be the path to some image you're using. It will get string split at the / character, and the func only takes the last element of that splitting\n",
    "    save_path is the folder you want to save to...recommended to also add something to the start of the images names to make it clear what you did to them (e.g. 'Regridded/regrid_')\n",
    "    '''\n",
    "    \n",
    "    #just setup an fits HDU from the data\n",
    "    hdu_new = fits.PrimaryHDU(array, header=wcs_header)\n",
    "    hdul = fits.HDUList([hdu_new])\n",
    "    \n",
    "        #saving the file\n",
    "    #         name_fixfit = name[:-3] + 'fits'\n",
    "#         new_filename = name_fixfit.split('/')[-1]  #grabs the file name we were using from before\n",
    "#         hdul.writeto(save_path+new_filename, overwrite=True)\n",
    "    hdul.writeto(save_path+name, overwrite=True)     \n",
    "    return (save_path+name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db26fe8",
   "metadata": {},
   "source": [
    "# Applying Baseline Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "081edd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up some initial lists\n",
    "\n",
    "from pybaselines import Baseline, misc #, utils\n",
    "from scipy.signal import medfilt, savgol_filter\n",
    "\n",
    "#used for plotting\n",
    "protostar_names = ['IRAS 16253-2429', 'B335', 'HOPS 153', 'HOPS 370', 'IRAS 20126+4104'] \n",
    "\n",
    "#the original data\n",
    "#at some point might help to swap to glob.glob if we use different directory structure\n",
    "#the original data\n",
    "cube_file_list = ['IRAS16253/jw01802-o015_t012_nirspec_g395m-f290lp_crop1_wcs1_s3d.fits', \\\n",
    "                    'B335/jw01802-o003_t001_nirspec_g395m-f290lp_crop1_wcs1_s3d.fits', \\\n",
    "                    'HOPS153/jw01802-o019_t015_nirspec_g395m-f290lp_crop1_wcs1_s3d.fits', \\\n",
    "                    'HOPS370/jw01802-o007_t004_nirspec_g395m-f290lp_crop1_wcs1_s3d.fits', \\\n",
    "                    '12_22_23_20126_update/jw01802-o011_t007_nirspec_g395m-f290lp_wcs1_s3d.fits'\n",
    "                    # 'IRAS20126/jw01802-o011_t007_nirspec_g395m-f290lp_crop1_wcs1_s3d.fits'\n",
    "                    ]\n",
    "\n",
    "#alternatively...#defining the paths by hand since in theory we only have 5 to do\n",
    "#I opt to store in in individual folders to catch name issues early...\n",
    "# protostar_folders = ['IRAS16253/', 'B335/', 'HOPS153/', 'HOPS370/', 'IRAS20126/']\n",
    "# cube_file_list = [glob(i + '*.fits')[0].replace('\\\\', '/') for i in protostar_folders] #change the wildcard '*' here!\n",
    "\n",
    "#derived data or cubes\n",
    "protostar_substr = ['IRAS16253', 'B335', 'HOPS153', 'HOPS370', 'IRAS20126']\n",
    "absorb_emiss_path = 'Extended_CO_CO2/CO_Absorption_Emission_Maps/'\n",
    "absorb_emiss_cube_list = [glob(absorb_emiss_path + i + '*cube*.fits')[0].replace('\\\\', '/') for i in protostar_substr]\n",
    "absorb_emiss_txt_list = [glob(absorb_emiss_path + i + '*txt')[0].replace('\\\\', '/') for i in protostar_substr]\n",
    "\n",
    "# central_sources = [(46.57459417809592, 45.12978229),  (46.73250708463416, 43.13112798), \\\n",
    "                #    (46.47088442936513, 46.6279981), (41.71119797770727, 43.61467905), \\\n",
    "                    # (43.38667807448542, 43.15705917)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d2f466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_1916\\3462307022.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  transmission_arr[:,i,j] = 1.0 + ice_arr[:,i,j]/cont_arr[:,i,j]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_1916\\3462307022.py:114: RuntimeWarning: invalid value encountered in log\n",
      "  tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_1916\\3462307022.py:114: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:  Baseline/IRAS16253_NIRspec_cube_tophat_jcbd.fits\n",
      "Saved:  Baseline_Subtracted/IRAS16253_NIRspec_cube_basefit_tophat_jcbd.fits\n",
      "Saved:  Continuum/IRAS16253_NIRspec_cube_pspline_asls_cont.fits\n",
      "Saved:  Continuum/IRAS16253_NIRspec_Continuum_sum.fits\n",
      "Saved:  Continuum/IRAS16253_NIRspec_Continuum_med.fits\n",
      "Saved:  Continuum/IRAS16253_NIRspec_Continuum_mean.fits\n",
      "Saved:  Ices/IRAS16253_NIRspec_cube_pspline_asls_ice.fits\n",
      "Saved:  Ices/IRAS16253_NIRspec_cube_pspline_asls_transmission.fits\n",
      "Saved:  Ices/IRAS16253_NIRspec_cube_pspline_asls_icetau.fits\n"
     ]
    }
   ],
   "source": [
    "# Let's try making a baseline image while looping through wavelengths; for IRAS 16253 here\n",
    "\n",
    "#params to smooth out data\n",
    "N_res = 100. * 1e-3 #knowing that average spectral resolution for the instrument is about 1/1000 microns, then applying multiples of that\n",
    "wave_cutoff_list = np.array([4.19, 4.32, 4.37, 4.4, 4.62, 4.86, 4.971])\n",
    "smooth_list = [1, 1, 10, 1, 5, 3, 5, 2] #smoothing parameters for baseline #third to last originally 3\n",
    "alpha_list = [1, 100, 50, 100, 1, 100, 5, 7] #regularization parameter (relative levels of noise and signal)\n",
    "\n",
    "#go through ONE file / protostar\n",
    "filepath = cube_file_list[0]\n",
    "\n",
    "#open and read a data file\n",
    "protostar_id = filepath.split('/')[0] # for reference later when saving files\n",
    "hdul = fits.open(filepath)\n",
    "jwst_cube = SpectralCube.read(hdul[1]) #accessing the cube for data  \n",
    "jwst_cube_wave = np.array(jwst_cube.spectral_axis.value, dtype=np.float64)[1:-1] #cut ends off data\n",
    "jwst_data = np.array(np.nan_to_num(jwst_cube._data), dtype=np.float64)[1:-1]\n",
    "err_cube = hdul['ERR'].data[1:-1]\n",
    "\n",
    "#figuring out units\n",
    "photometric_head = hdul[1].header\n",
    "delta_lambda = photometric_head['CDELT3'] #in microns ?\n",
    "pixel_area = photometric_head['PIXAR_SR'] # in sr\n",
    "'''\n",
    "pixel units for JWST are MJy/sr, the sr card is PIXAR_SR, ignore for now\n",
    "then MJy to cgs is 1e6*1 Jy/sr = 1e6 * 1e-23 erg/s/cm^2/spectral bandwidth in frequency, Hz per sr\n",
    "\n",
    "that is per frequency bandwidth! must multiply by it...\n",
    "since we only have the frequency band, we can convert by c = lam * nu, bandwidth=delta_nu = c/lam^2 * delta_lambda\n",
    "and then we must multiply by this bandwidth: have 1e6 * 1e-23 * c/lam^2 * delta_lambda * sr\n",
    "\n",
    "c units must change for what wavelength we use...here we use microns, so c in micron/sec is 3e8 m/s * (1e6 mic/m)\n",
    "so c = ~3e14\n",
    "\n",
    "and to prep in the loop, for each cube we will grab the delta_lambda and the pixel_area in sr\n",
    "'''\n",
    "cube_units = 1e6 * 1e-23 * 3e14/(jwst_cube_wave[:, None, None])**2. * pixel_area \n",
    "\n",
    "#set up arrays to be read in...\n",
    "baseline_fit_arr = np.zeros((jwst_data.shape)) #assume square, initialize as zeros\n",
    "resid_arr = np.zeros((jwst_data.shape)) #assume square, initialize as zeros\n",
    "cont_arr = np.zeros((jwst_data.shape))\n",
    "ice_arr = np.zeros((jwst_data.shape))\n",
    "transmission_arr = np.zeros((jwst_data.shape))\n",
    "tau_ice_arr = np.zeros((jwst_data.shape))\n",
    "\n",
    "#compute our fitted baseline of continuum+ices with a single baseline first with an initial tophat filter estimation\n",
    "# baseline_smoother = coeffs_list[-1][len(unres_wavelengths):len(unres_wavelengths)+len(smooth_list)]    \n",
    "baseline_fitter_global = Baseline(jwst_cube_wave, check_finite=True) #generic preset the baseline object given a list of x-values (wavelengths)\n",
    "#by explicit loops\n",
    "for i in range(jwst_data.shape[1]):\n",
    "    for j in range(jwst_data.shape[2]):\n",
    "        #access cube to separate out an initial estimate for the baseline\n",
    "        bkg_top = baseline_fitter_global.tophat(jwst_data[:,i,j], half_window=3)[0]\n",
    "\n",
    "        #begin to loop through different parameters, defining a new baseline for a given section of the spectrum\n",
    "        # baseline_alpha = stacked_coeffs[len(unres_wavelengths):, i, j] #need to gather our parameter, alpha\n",
    "        baseline_list = np.array([])\n",
    "\n",
    "        #formulating regimes to cutoff the spectrum and apply different smoothing factors\n",
    "        # cutoffs_flux_matched = bkg_top[[np.abs(wave - i).argmin() for i in wave_cutoff_list]]\n",
    "\n",
    "        #if edge case at start, do it by hand to omit conditionals\n",
    "        cutoff_mask = jwst_cube_wave < wave_cutoff_list[0] #define mask up to first marker\n",
    "        baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)     #compute baseline\n",
    "        baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[0],alpha=alpha_list[0])[0]\n",
    "        baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "        #if between two values and not at the edge cases, we loop..\n",
    "        cutoff_ind = 1 #to count loops\n",
    "        while cutoff_ind <= len(wave_cutoff_list)-1:\n",
    "            idx = (jwst_cube_wave >= wave_cutoff_list[cutoff_ind-1]) & (jwst_cube_wave <= wave_cutoff_list[cutoff_ind]) #logical masks joined with *\n",
    "            cutoff_mask = np.where(idx)[0] #determine mask between two values\n",
    "\n",
    "            #compute baseline\n",
    "            baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)\n",
    "\n",
    "            #check if relatively high S/N or not...if so, can do way following approx bottoms, else take median\n",
    "            if np.mean(jwst_data[:,i,j][cutoff_mask] / err_cube[:,i,j][cutoff_mask]) < 8 and cutoff_ind != 1 and cutoff_ind != len(wave_cutoff_list)-1:\n",
    "                baseline = baseline_fitter.pspline_asls(jwst_data[:,i,j][cutoff_mask], lam=5e6, p=0.45, spline_degree=2)[0] \n",
    "            elif np.mean(jwst_data[:,i,j][cutoff_mask] / err_cube[:,i,j][cutoff_mask]) < 8:\n",
    "                baseline = baseline_fitter.noise_median(bkg_top[cutoff_mask], half_window=6)[0] \n",
    "                baseline = baseline_fitter.pspline_asls(baseline, lam=5e1, p=0.5, spline_degree=2)[0] \n",
    "                # baseline = baseline_fitter.jbcd(baseline, half_window=2,alpha=5)[0]\n",
    "            else: #default to original if we can't figure anything else out...good for high S/N data\n",
    "                baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]\n",
    "                # baseline = baseline_fitter.pspline_asls(flux_1pix[cutoff_mask], lam=1e4, p=0.3, spline_degree=3)[0]\n",
    "            baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "            #update counter for loop, do after everything else\n",
    "            cutoff_ind += 1\n",
    "\n",
    "        #if edge case at end, do it by hand\n",
    "        cutoff_mask = jwst_cube_wave > wave_cutoff_list[-1] #define mask past last marker\n",
    "        baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)     #compute baseline\n",
    "        if np.mean(jwst_data[:,i,j][cutoff_mask] / err_cube[:,i,j][cutoff_mask]) < 8:\n",
    "            baseline = baseline_fitter.pspline_asls(jwst_data[:,i,j][cutoff_mask], lam=5e5, p=0.4, spline_degree=2)[0] #, half_window=smooth_list[-1],alpha=alpha_list[-1])[0]\n",
    "        else:\n",
    "            baseline = baseline_fitter.pspline_asls(jwst_data[:,i,j][cutoff_mask], lam=1e3, p=0.1, spline_degree=3)[0] #, half_window=smooth_list[-1],alpha=alpha_list[-1])[0]\n",
    "        baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "        #now trying to filter around our control or anchor points\n",
    "        for cutoff_ind in range(len(wave_cutoff_list)):\n",
    "            idx = ( jwst_cube_wave >= (wave_cutoff_list[cutoff_ind]-N_res) ) & ( jwst_cube_wave <= (wave_cutoff_list[cutoff_ind]+N_res) ) #logical masks joined with * using N_res\n",
    "            idx_mask = np.where(idx)[0] #making mask\n",
    "            baseline_list[idx_mask] = savgol_filter(baseline_list[idx_mask], polyorder=1, window_length=7) #in region around mask, apply filters\n",
    "\n",
    "        #storing data into arrays!!!\n",
    "        baseline_fit_arr[:,i,j] = baseline_list \n",
    "        resid_arr[:,i,j] = jwst_data[:,i,j]  - baseline_list   \n",
    "        cont_arr[:,i,j] = baseline_fitter_global.pspline_asls(baseline_list, lam=1e3, p=0.99, spline_degree=2)[0]  \n",
    "        ice_arr[:,i,j] = baseline_list - cont_arr[:,i,j] \n",
    "        transmission_arr[:,i,j] = 1.0 + ice_arr[:,i,j]/cont_arr[:,i,j]\n",
    "        tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])    \n",
    "    \n",
    "\n",
    "#tests to check shapes are correct\n",
    "# print('JWST: ', jwst_data.shape, ' Splined baseline Cube: ', baseline_fit_arr.shape, ' Summed baseline: ', baseline_sum_arr.shape,)\n",
    "#saving baseline as cube, not summed, with MJy/sr\n",
    "astropy_cube_units = u.MJy/u.sr #need to define units\n",
    "\n",
    "#saving baseline as cube, not summed, with MJy/sr\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=baseline_fit_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "# cube = cube.with_spectral_unit(u.um)\n",
    "cube_savepath = 'Baseline/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_tophat_jcbd.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline_subtracted cube, with MJy/sr\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "nocont_cube = SpectralCube(data=resid_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "# nocont_cube = cube.with_spectral_unit(u.um)\n",
    "nocont_cube_savepath = 'Baseline_Subtracted/'\n",
    "nocont_cube_name = protostar_id + '_NIRspec_cube_basefit_tophat_jcbd.fits'\n",
    "nocont_cube.write(nocont_cube_savepath+nocont_cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', nocont_cube_savepath+nocont_cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, with cgs units\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=cont_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Continuum/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_cont.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#ways to average baselines and also develope a header for relevant usage\n",
    "continuum_sum_arr = np.sum(cube_units* cont_arr, axis=0)\n",
    "continuum_med_arr = np.median(cube_units * cont_arr, axis=0)\n",
    "continuum_mean_arr = np.mean(cube_units * cont_arr, axis=0)\n",
    "continuum_header = jwst_cube.header #need to edit header a bit\n",
    "continuum_header['BUNIT'] = 'erg cm-2 s-1 sr-1' \n",
    "continuum_header['CUNIT3'] = 'um'\n",
    "continuum_header['HISTORY'] = 'The following steps apply: converted to cgs units (erg/s/cm^2/sr). Then baseline is averaged accordingly.'\n",
    "\n",
    "#saving summed cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_sum'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_sum_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#saving median cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_med'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_med_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#saving mean cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_mean'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_mean_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#given continuum, compute ices\n",
    "\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=ice_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_ice.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, could be with cgs units, but here is just a ratio...\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=transmission_arr, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_transmission.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, with cgs units\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=tau_ice_arr, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_icetau.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7b2120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c127da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abdd70c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_1916\\2738523130.py:103: RuntimeWarning: invalid value encountered in true_divide\n",
      "  elif np.mean(jwst_data[:,i,j][cutoff_mask] / bkg_top[cutoff_mask]) > 1.1: #next, have to check the averaged signal to noise...compare to tophat and see if > 10% of it\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_1916\\2738523130.py:138: RuntimeWarning: invalid value encountered in true_divide\n",
      "  transmission_arr[:,i,j] = 1.0 + ice_arr[:,i,j]/cont_arr[:,i,j]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_1916\\2738523130.py:103: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  elif np.mean(jwst_data[:,i,j][cutoff_mask] / bkg_top[cutoff_mask]) > 1.1: #next, have to check the averaged signal to noise...compare to tophat and see if > 10% of it\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_1916\\2738523130.py:139: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_1916\\2738523130.py:139: RuntimeWarning: invalid value encountered in log\n",
      "  tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:  Baseline/B335_NIRspec_cube_tophat_jcbd.fits\n",
      "Saved:  Baseline_Subtracted/B335_NIRspec_cube_basefit_tophat_jcbd.fits\n",
      "Saved:  Continuum/B335_NIRspec_cube_pspline_asls_cont.fits\n",
      "Saved:  Continuum/B335_NIRspec_Continuum_sum.fits\n",
      "Saved:  Continuum/B335_NIRspec_Continuum_med.fits\n",
      "Saved:  Continuum/B335_NIRspec_Continuum_mean.fits\n",
      "Saved:  Ices/B335_NIRspec_cube_pspline_asls_ice.fits\n",
      "Saved:  Ices/B335_NIRspec_cube_pspline_asls_transmission.fits\n",
      "Saved:  Ices/B335_NIRspec_cube_pspline_asls_icetau.fits\n"
     ]
    }
   ],
   "source": [
    "# Let's try making a baseline image while looping through wavelengths\n",
    "\n",
    "#params to smooth out data\n",
    "N_res = 100. * 1e-3 #knowing that average spectral resolution for the instrument is about 1/1000 microns, then applying multiples of that\n",
    "wave_cutoff_list = np.array([4.19, 4.32, 4.37, 4.415, 4.62, 4.72, 4.87, 4.941])\n",
    "smooth_list = [1, 1, 10, 1, 5, 3, 7, 2, 10] #smoothing parameters for baseline #third to last originally 3\n",
    "alpha_list = [1, 100, 50, 100, 3, 100, 100, 7, 0.1] #regularization parameter (relative levels of noise and signal)\n",
    "\n",
    "#go through ONE file / protostar\n",
    "protostar_count = 1\n",
    "filepath = cube_file_list[protostar_count]\n",
    "\n",
    "#read in a cube that shows if each co line is in emission or absorption\n",
    "cube_absorb_emiss = fits.getdata(absorb_emiss_cube_list[protostar_count])\n",
    "co_refs_txt = np.genfromtxt(absorb_emiss_txt_list[protostar_count], delimiter=',', skip_header=1) # text file used to match indices to a given CO line\n",
    "\n",
    "#open and read a data file\n",
    "protostar_id = filepath.split('/')[0] # for reference later when saving files\n",
    "hdul = fits.open(filepath)\n",
    "jwst_cube = SpectralCube.read(hdul[1]) #accessing the cube for data  \n",
    "jwst_cube_wave = np.array(jwst_cube.spectral_axis.value, dtype=np.float64)[1:-1] #cut ends off data\n",
    "jwst_data = np.array(np.nan_to_num(jwst_cube._data), dtype=np.float64)[1:-1]\n",
    "err_cube = hdul['ERR'].data[1:-1]\n",
    "\n",
    "#figuring out units\n",
    "photometric_head = hdul[1].header\n",
    "delta_lambda = photometric_head['CDELT3'] #in microns ?\n",
    "pixel_area = photometric_head['PIXAR_SR'] # in sr\n",
    "'''\n",
    "pixel units for JWST are MJy/sr, the sr card is PIXAR_SR, ignore for now\n",
    "then MJy to cgs is 1e6*1 Jy/sr = 1e6 * 1e-23 erg/s/cm^2/spectral bandwidth in frequency, Hz per sr\n",
    "\n",
    "that is per frequency bandwidth! must multiply by it...\n",
    "since we only have the frequency band, we can convert by c = lam * nu, bandwidth=delta_nu = c/lam^2 * delta_lambda\n",
    "and then we must multiply by this bandwidth: have 1e6 * 1e-23 * c/lam^2 * delta_lambda * sr\n",
    "\n",
    "c units must change for what wavelength we use...here we use microns, so c in micron/sec is 3e8 m/s * (1e6 mic/m)\n",
    "so c = ~3e14\n",
    "\n",
    "and to prep in the loop, for each cube we will grab the delta_lambda and the pixel_area in sr\n",
    "'''\n",
    "cube_units = 1e6 * 1e-23 * 3e14/(jwst_cube_wave[:, None, None])**2. * pixel_area \n",
    "\n",
    "#set up arrays to be read in...\n",
    "baseline_fit_arr = np.zeros((jwst_data.shape)) #assume square, initialize as zeros\n",
    "resid_arr = np.zeros((jwst_data.shape)) #assume square, initialize as zeros\n",
    "cont_arr = np.zeros((jwst_data.shape))\n",
    "ice_arr = np.zeros((jwst_data.shape))\n",
    "transmission_arr = np.zeros((jwst_data.shape))\n",
    "tau_ice_arr = np.zeros((jwst_data.shape))\n",
    "\n",
    "#compute our fitted baseline of continuum+ices with a single baseline first with an initial tophat filter estimation\n",
    "# baseline_smoother = coeffs_list[-1][len(unres_wavelengths):len(unres_wavelengths)+len(smooth_list)]    \n",
    "baseline_fitter_global = Baseline(jwst_cube_wave, check_finite=True) #generic preset the baseline object given a list of x-values (wavelengths)\n",
    "#by explicit loops\n",
    "for i in range(jwst_data.shape[1]):\n",
    "    for j in range(jwst_data.shape[2]):\n",
    "        #access cube to separate out an initial estimate for the baseline\n",
    "        bkg_top = baseline_fitter_global.tophat(jwst_data[:,i,j], half_window=3)[0]\n",
    "\n",
    "        #begin to loop through different parameters, defining a new baseline for a given section of the spectrum\n",
    "        # baseline_alpha = stacked_coeffs[len(unres_wavelengths):, i, j] #need to gather our parameter, alpha\n",
    "        baseline_list = np.array([])\n",
    "\n",
    "        #formulating regimes to cutoff the spectrum and apply different smoothing factors\n",
    "        # cutoffs_flux_matched = bkg_top[[np.abs(wave - i).argmin() for i in wave_cutoff_list]]\n",
    "\n",
    "        #if edge case at start, do it by hand to omit conditionals\n",
    "        cutoff_mask = jwst_cube_wave < wave_cutoff_list[0] #define mask up to first marker\n",
    "        baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)     #compute baseline\n",
    "        baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[0],alpha=alpha_list[0])[0]\n",
    "        baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "        #if between two values and not at the edge cases, we loop..\n",
    "        cutoff_ind = 1 #to count loops\n",
    "        while cutoff_ind <= len(wave_cutoff_list)-1:\n",
    "            #take region of spectrum\n",
    "            idx = (jwst_cube_wave >= wave_cutoff_list[cutoff_ind-1]) & (jwst_cube_wave <= wave_cutoff_list[cutoff_ind]) #logical masks joined with * or & from PRIOR breakpoint\n",
    "            cutoff_mask = np.where(idx)[0] #determine mask between two values\n",
    "            baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)\n",
    "\n",
    "            #loop through many CO spectral lines to determine each individual baseline \n",
    "            if wave_cutoff_list[cutoff_ind] < 4.45: # len(co_line_wave_mask) == 0: #first check if we have to either by # of CO lines or wavelength itself\n",
    "                baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]\n",
    "            else:\n",
    "                #given newly updated cutoffs, we compute the mode of the region to see if mostly absorption or emission\n",
    "                co_line_wave_mask = np.where((co_refs_txt[:, 1] >= wave_cutoff_list[cutoff_ind-1]) \\\n",
    "                                    & (co_refs_txt[:, 1] <= wave_cutoff_list[cutoff_ind]))[0]\n",
    "                line_absorb_emiss_match = cube_absorb_emiss[co_line_wave_mask, i, j]\n",
    "                vals, counts = np.unique(line_absorb_emiss_match, return_counts=True) #find number of unique elements of -1, 1, or 0 to determine bool\n",
    "                absorb_emiss_mode = vals[np.argmax(counts)] #count bools to determine mode\n",
    "\n",
    "                #now using the mode to pick and compute the correct baseline\n",
    "                if absorb_emiss_mode == 1 and (cutoff_ind == len(wave_cutoff_list)-1 or cutoff_ind == len(wave_cutoff_list)-2) \\\n",
    "                                                             and np.mean(jwst_data[:,i,j][cutoff_mask]  / err_cube[:,i,j][cutoff_mask]) < 8: #emission, do old way\n",
    "                    baseline = baseline_fitter.pspline_asls(jwst_data[:,i,j][cutoff_mask] , lam=1e5, p=0.15, spline_degree=3)[0]\n",
    "                elif absorb_emiss_mode == 1: #emission, do old way\n",
    "                    baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]\n",
    "                    # baseline = baseline_fitter.asls(flux_1pix[cutoff_mask], lam=1e2, p=0.9)[0]\n",
    "                elif absorb_emiss_mode == -1: #absorption, change slightly\n",
    "                    baseline = baseline_fitter.pspline_asls(jwst_data[:,i,j][cutoff_mask], p=0.9, lam=5e1)[0]\n",
    "                    # baseline = baseline_fitter.noise_median(flux_1pix[cutoff_mask], half_window=2)[0] \n",
    "                elif np.mean(jwst_data[:,i,j][cutoff_mask] / bkg_top[cutoff_mask]) > 1.1: #next, have to check the averaged signal to noise...compare to tophat and see if > 10% of it\n",
    "                        baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]\n",
    "                else: #default to original if we can't figure anything else out...\n",
    "                    # baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]\n",
    "                    baseline = baseline_fitter.noise_median(jwst_data[:,i,j][cutoff_mask], half_window=2)[0] \n",
    "            baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "            #update counter for loop, do after everything else\n",
    "            cutoff_ind += 1\n",
    "\n",
    "        #if edge case at end, do it by hand\n",
    "        cutoff_mask = jwst_cube_wave > wave_cutoff_list[-1] #define mask past last marker\n",
    "        baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)     #compute baseline\n",
    "        #given newly updated cutoffs, we compute the mode of the region to see if mostly absorption or emission\n",
    "        co_line_wave_mask = np.where((co_refs_txt[:, 1] >=  wave_cutoff_list[-1]))[0]\n",
    "        line_absorb_emiss_match = cube_absorb_emiss[co_line_wave_mask, i, j]\n",
    "        vals, counts = np.unique(line_absorb_emiss_match, return_counts=True) #find number of unique elements of -1, 1, or 0 to determine bool\n",
    "        absorb_emiss_mode = vals[np.argmax(counts)] #count bools to determine mode\n",
    "        #now can fit the last portion for real!\n",
    "        if absorb_emiss_mode == 1 and np.mean(jwst_data[:,i,j][cutoff_mask]  / err_cube[:,i,j][cutoff_mask]) < 8: #emission, do old way\n",
    "            baseline = baseline_fitter.pspline_asls(jwst_data[:,i,j][cutoff_mask], lam=1e4, p=0.1, spline_degree=3)[0] \n",
    "        # if absorb_emiss_mode == 1:\n",
    "        #     baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[-1],alpha=alpha_list[-1])[0]\n",
    "        # elif absorb_emiss_mode == -1: \n",
    "        #     baseline = baseline_fitter.pspline_asls(bkg_top[cutoff_mask], lam=1e2, p=0.999, spline_degree=2)[0]\n",
    "        else:\n",
    "            # baseline = baseline_fitter.noise_median(flux_1pix[cutoff_mask], half_window=20)[0] \n",
    "            baseline = baseline_fitter.pspline_asls(bkg_top[cutoff_mask], lam=2e2, p=0.9, spline_degree=3)[0]\n",
    "        baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "        #storing data into arrays!!!\n",
    "        baseline_fit_arr[:,i,j] = baseline_list \n",
    "        resid_arr[:,i,j] = jwst_data[:,i,j]  - baseline_list   \n",
    "        cont_arr[:,i,j] = baseline_fitter_global.pspline_asls(baseline_list, lam=1e2, p=0.9999, spline_degree=2)[0]  \n",
    "        ice_arr[:,i,j] = baseline_list - cont_arr[:,i,j] \n",
    "        transmission_arr[:,i,j] = 1.0 + ice_arr[:,i,j]/cont_arr[:,i,j]\n",
    "        tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])    \n",
    "    \n",
    "\n",
    "#tests to check shapes are correct\n",
    "# print('JWST: ', jwst_data.shape, ' Splined baseline Cube: ', baseline_fit_arr.shape, ' Summed baseline: ', baseline_sum_arr.shape,)\n",
    "#saving baseline as cube, not summed, with MJy/sr\n",
    "astropy_cube_units = u.MJy/u.sr #need to define units\n",
    "\n",
    "#saving baseline as cube, not summed, with MJy/sr\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=baseline_fit_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "# cube = cube.with_spectral_unit(u.um)\n",
    "cube_savepath = 'Baseline/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_tophat_jcbd.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline_subtracted cube, with MJy/sr\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "nocont_cube = SpectralCube(data=resid_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "# nocont_cube = cube.with_spectral_unit(u.um)\n",
    "nocont_cube_savepath = 'Baseline_Subtracted/'\n",
    "nocont_cube_name = protostar_id + '_NIRspec_cube_basefit_tophat_jcbd.fits'\n",
    "nocont_cube.write(nocont_cube_savepath+nocont_cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', nocont_cube_savepath+nocont_cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, with cgs units\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=cont_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Continuum/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_cont.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#ways to average baselines and also develope a header for relevant usage\n",
    "continuum_sum_arr = np.sum(cube_units* cont_arr, axis=0)\n",
    "continuum_med_arr = np.median(cube_units * cont_arr, axis=0)\n",
    "continuum_mean_arr = np.mean(cube_units * cont_arr, axis=0)\n",
    "continuum_header = jwst_cube.header #need to edit header a bit\n",
    "continuum_header['BUNIT'] = 'erg cm-2 s-1 sr-1' \n",
    "continuum_header['CUNIT3'] = 'um'\n",
    "continuum_header['HISTORY'] = 'The following steps apply: converted to cgs units (erg/s/cm^2/sr). Then baseline is averaged accordingly.'\n",
    "\n",
    "#saving summed cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_sum'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_sum_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#saving median cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_med'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_med_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#saving mean cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_mean'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_mean_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#given continuum, compute ices\n",
    "\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=ice_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_ice.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, could be with cgs units, but here is just a ratio...\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=transmission_arr, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_transmission.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, with cgs units\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=tau_ice_arr, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_icetau.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55895edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e45a747d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_27496\\686157052.py:109: RuntimeWarning: invalid value encountered in true_divide\n",
      "  transmission_arr[:,i,j] = 1.0 + ice_arr[:,i,j]/cont_arr[:,i,j]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_27496\\686157052.py:110: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_27496\\686157052.py:110: RuntimeWarning: invalid value encountered in log\n",
      "  tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:  Baseline/HOPS153_NIRspec_cube_tophat_jcbd.fits\n",
      "Saved:  Baseline_Subtracted/HOPS153_NIRspec_cube_basefit_tophat_jcbd.fits\n",
      "Saved:  Continuum/HOPS153_NIRspec_cube_pspline_asls_cont.fits\n",
      "Saved:  Continuum/HOPS153_NIRspec_Continuum_sum.fits\n",
      "Saved:  Continuum/HOPS153_NIRspec_Continuum_med.fits\n",
      "Saved:  Continuum/HOPS153_NIRspec_Continuum_mean.fits\n",
      "Saved:  Ices/HOPS153_NIRspec_cube_pspline_asls_ice.fits\n",
      "Saved:  Ices/HOPS153_NIRspec_cube_pspline_asls_transmission.fits\n",
      "Saved:  Ices/HOPS153_NIRspec_cube_pspline_asls_icetau.fits\n"
     ]
    }
   ],
   "source": [
    "# Let's try making a baseline image while looping through wavelengths\n",
    "\n",
    "#params to smooth out data\n",
    "N_res = 100. * 1e-3 #knowing that average spectral resolution for the instrument is about 1/1000 microns, then applying multiples of that\n",
    "wave_cutoff_list = np.array([4.19, 4.32, 4.37, 4.4, 4.62, 4.72, 4.87, 4.939])\n",
    "smooth_list = [1, 1, 10, 1, 5, 3, 1, 2, 10] #smoothing parameters for baseline #third to last originally 3\n",
    "alpha_list = [1, 100, 50, 100, 3, 100, 100, 7, 1] #regularization parameter (relative levels of noise and signal)\n",
    "\n",
    "#go through ONE file / protostar\n",
    "protostar_count = 2\n",
    "filepath = cube_file_list[protostar_count]\n",
    "\n",
    "#read in a cube that shows if each co line is in emission or absorption\n",
    "cube_absorb_emiss = fits.getdata(absorb_emiss_cube_list[protostar_count])\n",
    "co_refs_txt = np.genfromtxt(absorb_emiss_txt_list[protostar_count], delimiter=',', skip_header=1) # text file used to match indices to a given CO line\n",
    "\n",
    "#open and read a data file\n",
    "protostar_id = filepath.split('/')[0] # for reference later when saving files\n",
    "hdul = fits.open(filepath)\n",
    "jwst_cube = SpectralCube.read(hdul[1]) #accessing the cube for data  \n",
    "jwst_cube_wave = np.array(jwst_cube.spectral_axis.value, dtype=np.float64)[1:-1] #cut ends off data\n",
    "jwst_data = np.array(np.nan_to_num(jwst_cube._data), dtype=np.float64)[1:-1]\n",
    "err_cube = hdul['ERR'].data[1:-1]\n",
    "\n",
    "#figuring out units\n",
    "photometric_head = hdul[1].header\n",
    "delta_lambda = photometric_head['CDELT3'] #in microns ?\n",
    "pixel_area = photometric_head['PIXAR_SR'] # in sr\n",
    "'''\n",
    "pixel units for JWST are MJy/sr, the sr card is PIXAR_SR, ignore for now\n",
    "then MJy to cgs is 1e6*1 Jy/sr = 1e6 * 1e-23 erg/s/cm^2/spectral bandwidth in frequency, Hz per sr\n",
    "\n",
    "that is per frequency bandwidth! must multiply by it...\n",
    "since we only have the frequency band, we can convert by c = lam * nu, bandwidth=delta_nu = c/lam^2 * delta_lambda\n",
    "and then we must multiply by this bandwidth: have 1e6 * 1e-23 * c/lam^2 * delta_lambda * sr\n",
    "\n",
    "c units must change for what wavelength we use...here we use microns, so c in micron/sec is 3e8 m/s * (1e6 mic/m)\n",
    "so c = ~3e14\n",
    "\n",
    "and to prep in the loop, for each cube we will grab the delta_lambda and the pixel_area in sr\n",
    "'''\n",
    "cube_units = 1e6 * 1e-23 * 3e14/(jwst_cube_wave[:, None, None])**2. * pixel_area \n",
    "\n",
    "#set up arrays to be read in...\n",
    "baseline_fit_arr = np.zeros((jwst_data.shape)) #assume square, initialize as zeros\n",
    "resid_arr = np.zeros((jwst_data.shape)) #assume square, initialize as zeros\n",
    "cont_arr = np.zeros((jwst_data.shape))\n",
    "ice_arr = np.zeros((jwst_data.shape))\n",
    "transmission_arr = np.zeros((jwst_data.shape))\n",
    "tau_ice_arr = np.zeros((jwst_data.shape))\n",
    "\n",
    "#compute our fitted baseline of continuum+ices with a single baseline first with an initial tophat filter estimation\n",
    "# baseline_smoother = coeffs_list[-1][len(unres_wavelengths):len(unres_wavelengths)+len(smooth_list)]    \n",
    "baseline_fitter_global = Baseline(jwst_cube_wave, check_finite=True) #generic preset the baseline object given a list of x-values (wavelengths)\n",
    "#by explicit loops\n",
    "for i in range(jwst_data.shape[1]):\n",
    "    for j in range(jwst_data.shape[2]):\n",
    "        #access cube to separate out an initial estimate for the baseline\n",
    "        bkg_top = baseline_fitter_global.tophat(jwst_data[:,i,j], half_window=3)[0]\n",
    "\n",
    "        #begin to loop through different parameters, defining a new baseline for a given section of the spectrum\n",
    "        # baseline_alpha = stacked_coeffs[len(unres_wavelengths):, i, j] #need to gather our parameter, alpha\n",
    "        baseline_list = np.array([])\n",
    "\n",
    "        #formulating regimes to cutoff the spectrum and apply different smoothing factors\n",
    "        # cutoffs_flux_matched = bkg_top[[np.abs(wave - i).argmin() for i in wave_cutoff_list]]\n",
    "\n",
    "        #if edge case at start, do it by hand to omit conditionals\n",
    "        cutoff_mask = jwst_cube_wave < wave_cutoff_list[0] #define mask up to first marker\n",
    "        baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)     #compute baseline\n",
    "        baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[0],alpha=alpha_list[0])[0]\n",
    "        baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "        #if between two values and not at the edge cases, we loop..\n",
    "        cutoff_ind = 1 #to count loops\n",
    "        while cutoff_ind <= len(wave_cutoff_list)-1:\n",
    "            idx = (jwst_cube_wave >= wave_cutoff_list[cutoff_ind-1]) & (jwst_cube_wave <= wave_cutoff_list[cutoff_ind]) #logical masks joined with *\n",
    "            cutoff_mask = np.where(idx)[0] #determine mask between two values\n",
    "            # print('middle checks: ', cutoff_ind, wave_cutoff_list[cutoff_ind], len(flux_1pix[cutoff_mask]))\n",
    "\n",
    "            #compute baseline\n",
    "            baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)\n",
    "            baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]\n",
    "            baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "            #update counter for loop, do after everything else\n",
    "            cutoff_ind += 1\n",
    "\n",
    "        #if edge case at end, do it by hand\n",
    "        # print('end', wave_cutoff_list[-1]) #print to confirm cutoff at end\n",
    "        cutoff_mask = jwst_cube_wave > wave_cutoff_list[-1] #define mask past last marker\n",
    "        baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)     #compute baseline\n",
    "        # baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]\n",
    "        baseline = baseline_fitter.pspline_asls(bkg_top[cutoff_mask], lam=2e2, p=0.99, spline_degree=3)[0] #, half_window=smooth_list[-1],alpha=alpha_list[-1])[0]\n",
    "        baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "        #now trying to filter around our control or anchor points\n",
    "        N_res = 100. * 1e-3 #knowing that average spectral resolution for the instrument is about 1/1000 microns, then applying multiples of that\n",
    "        for cutoff_ind in range(len(wave_cutoff_list)):\n",
    "            idx = ( jwst_cube_wave >= (wave_cutoff_list[cutoff_ind]-N_res) ) & ( jwst_cube_wave <= (wave_cutoff_list[cutoff_ind]+N_res) ) #logical masks joined with * using N_res\n",
    "            idx_mask = np.where(idx)[0] #making mask\n",
    "            baseline_list[idx_mask] = savgol_filter(baseline_list[idx_mask], polyorder=1, window_length=7) #in region around mask, apply filters\n",
    "\n",
    "        #storing data into arrays!!!\n",
    "        baseline_fit_arr[:,i,j] = baseline_list \n",
    "        resid_arr[:,i,j] = jwst_data[:,i,j]  - baseline_list   \n",
    "        cont_arr[:,i,j] = baseline_fitter_global.pspline_asls(baseline_list, lam=1e2, p=0.9999, spline_degree=2)[0]  \n",
    "        ice_arr[:,i,j] = baseline_list - cont_arr[:,i,j] \n",
    "        transmission_arr[:,i,j] = 1.0 + ice_arr[:,i,j]/cont_arr[:,i,j]\n",
    "        tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])    \n",
    "    \n",
    "\n",
    "#tests to check shapes are correct\n",
    "# print('JWST: ', jwst_data.shape, ' Splined baseline Cube: ', baseline_fit_arr.shape, ' Summed baseline: ', baseline_sum_arr.shape,)\n",
    "#saving baseline as cube, not summed, with MJy/sr\n",
    "astropy_cube_units = u.MJy/u.sr #need to define units\n",
    "\n",
    "#saving baseline as cube, not summed, with MJy/sr\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=baseline_fit_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "# cube = cube.with_spectral_unit(u.um)\n",
    "cube_savepath = 'Baseline/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_tophat_jcbd.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline_subtracted cube, with MJy/sr\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "nocont_cube = SpectralCube(data=resid_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "# nocont_cube = cube.with_spectral_unit(u.um)\n",
    "nocont_cube_savepath = 'Baseline_Subtracted/'\n",
    "nocont_cube_name = protostar_id + '_NIRspec_cube_basefit_tophat_jcbd.fits'\n",
    "nocont_cube.write(nocont_cube_savepath+nocont_cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', nocont_cube_savepath+nocont_cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, with cgs units\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=cont_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Continuum/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_cont.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#ways to average baselines and also develope a header for relevant usage\n",
    "continuum_sum_arr = np.sum(cube_units* cont_arr, axis=0)\n",
    "continuum_med_arr = np.median(cube_units * cont_arr, axis=0)\n",
    "continuum_mean_arr = np.mean(cube_units * cont_arr, axis=0)\n",
    "continuum_header = jwst_cube.header #need to edit header a bit\n",
    "continuum_header['BUNIT'] = 'erg cm-2 s-1 sr-1' \n",
    "continuum_header['CUNIT3'] = 'um'\n",
    "continuum_header['HISTORY'] = 'The following steps apply: converted to cgs units (erg/s/cm^2/sr). Then baseline is averaged accordingly.'\n",
    "\n",
    "#saving summed cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_sum'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_sum_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#saving median cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_med'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_med_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#saving mean cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_mean'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_mean_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#given continuum, compute ices\n",
    "\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=ice_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_ice.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, could be with cgs units, but here is just a ratio...\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=transmission_arr, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_transmission.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, with cgs units\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=tau_ice_arr, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_icetau.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6ce3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "415bea6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_1916\\2688608263.py:150: RuntimeWarning: invalid value encountered in true_divide\n",
      "  transmission_arr[:,i,j] = 1.0 + ice_arr[:,i,j]/cont_arr[:,i,j]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_1916\\2688608263.py:151: RuntimeWarning: invalid value encountered in log\n",
      "  tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_1916\\2688608263.py:151: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:  Baseline/HOPS370_NIRspec_cube_tophat_jcbd.fits\n",
      "Saved:  Baseline_Subtracted/HOPS370_NIRspec_cube_basefit_tophat_jcbd.fits\n",
      "Saved:  Continuum/HOPS370_NIRspec_cube_pspline_asls_cont.fits\n",
      "Saved:  Continuum/HOPS370_NIRspec_Continuum_sum.fits\n",
      "Saved:  Continuum/HOPS370_NIRspec_Continuum_med.fits\n",
      "Saved:  Continuum/HOPS370_NIRspec_Continuum_mean.fits\n",
      "Saved:  Ices/HOPS370_NIRspec_cube_pspline_asls_ice.fits\n",
      "Saved:  Ices/HOPS370_NIRspec_cube_pspline_asls_transmission.fits\n",
      "Saved:  Ices/HOPS370_NIRspec_cube_pspline_asls_icetau.fits\n"
     ]
    }
   ],
   "source": [
    "# Let's try making a baseline image while looping through wavelengths\n",
    "\n",
    "#params to smooth out data\n",
    "N_res = 100. * 1e-3 #knowing that average spectral resolution for the instrument is about 1/1000 microns, then applying multiples of that\n",
    "wave_cutoff_list = np.array([4.19, 4.32, 4.37, 4.42, 4.58, 4.69, 4.79, 4.865, 4.939])\n",
    "smooth_list = [1, 1, 10, 1, 5, 1, 10, 10, 2] #smoothing parameters for baseline #third to last originally 3\n",
    "alpha_list = [1, 100, 50, 100, 3, 100, 1, 1, 7] #regularization parameter (relative levels of noise and signal)\n",
    "\n",
    "#go through ONE file / protostar\n",
    "protostar_count = 3\n",
    "filepath = cube_file_list[protostar_count]\n",
    "\n",
    "#read in a cube that shows if each co line is in emission or absorption\n",
    "cube_absorb_emiss = fits.getdata(absorb_emiss_cube_list[protostar_count])\n",
    "co_refs_txt = np.genfromtxt(absorb_emiss_txt_list[protostar_count], delimiter=',', skip_header=1) # text file used to match indices to a given CO line\n",
    "\n",
    "#open and read a data file\n",
    "protostar_id = filepath.split('/')[0] # for reference later when saving files\n",
    "hdul = fits.open(filepath)\n",
    "jwst_cube = SpectralCube.read(hdul[1]) #accessing the cube for data  \n",
    "jwst_cube_wave = np.array(jwst_cube.spectral_axis.value, dtype=np.float64)[1:-1] #cut ends off data\n",
    "jwst_data = np.array(np.nan_to_num(jwst_cube._data), dtype=np.float64)[1:-1]\n",
    "err_cube = hdul['ERR'].data[1:-1]\n",
    "\n",
    "#figuring out units\n",
    "photometric_head = hdul[1].header\n",
    "delta_lambda = photometric_head['CDELT3'] #in microns ?\n",
    "pixel_area = photometric_head['PIXAR_SR'] # in sr\n",
    "'''\n",
    "pixel units for JWST are MJy/sr, the sr card is PIXAR_SR, ignore for now\n",
    "then MJy to cgs is 1e6*1 Jy/sr = 1e6 * 1e-23 erg/s/cm^2/spectral bandwidth in frequency, Hz per sr\n",
    "\n",
    "that is per frequency bandwidth! must multiply by it...\n",
    "since we only have the frequency band, we can convert by c = lam * nu, bandwidth=delta_nu = c/lam^2 * delta_lambda\n",
    "and then we must multiply by this bandwidth: have 1e6 * 1e-23 * c/lam^2 * delta_lambda * sr\n",
    "\n",
    "c units must change for what wavelength we use...here we use microns, so c in micron/sec is 3e8 m/s * (1e6 mic/m)\n",
    "so c = ~3e14\n",
    "\n",
    "and to prep in the loop, for each cube we will grab the delta_lambda and the pixel_area in sr\n",
    "'''\n",
    "cube_units = 1e6 * 1e-23 * 3e14/(jwst_cube_wave[:, None, None])**2. * pixel_area \n",
    "\n",
    "#set up arrays to be read in...\n",
    "baseline_fit_arr = np.zeros((jwst_data.shape)) #assume square, initialize as zeros\n",
    "resid_arr = np.zeros((jwst_data.shape)) #assume square, initialize as zeros\n",
    "cont_arr = np.zeros((jwst_data.shape))\n",
    "ice_arr = np.zeros((jwst_data.shape))\n",
    "transmission_arr = np.zeros((jwst_data.shape))\n",
    "tau_ice_arr = np.zeros((jwst_data.shape))\n",
    "\n",
    "#compute our fitted baseline of continuum+ices with a single baseline first with an initial tophat filter estimation\n",
    "# baseline_smoother = coeffs_list[-1][len(unres_wavelengths):len(unres_wavelengths)+len(smooth_list)]    \n",
    "baseline_fitter_global = Baseline(jwst_cube_wave, check_finite=True) #generic preset the baseline object given a list of x-values (wavelengths)\n",
    "#by explicit loops\n",
    "for i in range(jwst_data.shape[1]):\n",
    "    for j in range(jwst_data.shape[2]):\n",
    "        #access cube to separate out an initial estimate for the baseline\n",
    "        bkg_top = baseline_fitter_global.tophat(jwst_data[:,i,j], half_window=3)[0]\n",
    "\n",
    "        #begin to loop through different parameters, defining a new baseline for a given section of the spectrum\n",
    "        # baseline_alpha = stacked_coeffs[len(unres_wavelengths):, i, j] #need to gather our parameter, alpha\n",
    "        baseline_list = np.array([])\n",
    "\n",
    "        #formulating regimes to cutoff the spectrum and apply different smoothing factors\n",
    "        # cutoffs_flux_matched = bkg_top[[np.abs(wave - i).argmin() for i in wave_cutoff_list]]\n",
    "\n",
    "        #if edge case at start, do it by hand to omit conditionals\n",
    "        cutoff_mask = jwst_cube_wave < wave_cutoff_list[0] #define mask up to first marker\n",
    "        baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)     #compute baseline\n",
    "        baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[0],alpha=alpha_list[0])[0]\n",
    "        baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "        #if between two values and not at the edge cases, we loop..\n",
    "        cutoff_ind = 1 #to count loops\n",
    "        while cutoff_ind <= len(wave_cutoff_list)-1:\n",
    "            #take region of spectrum\n",
    "            idx = (jwst_cube_wave >= wave_cutoff_list[cutoff_ind-1]) & (jwst_cube_wave <= wave_cutoff_list[cutoff_ind]) #logical masks joined with * or & from PRIOR breakpoint\n",
    "            cutoff_mask = np.where(idx)[0] #determine mask between two values\n",
    "            baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)\n",
    "\n",
    "            #loop through many CO spectral lines to determine each individual baseline \n",
    "            if wave_cutoff_list[cutoff_ind] < 4.41: # len(co_line_wave_mask) == 0: #first check if we have to either by # of CO lines or wavelength itself\n",
    "                baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]\n",
    "            else:\n",
    "                #given newly updated cutoffs, we compute the mode of the region to see if mostly absorption or emission\n",
    "                co_line_wave_mask = np.where((co_refs_txt[:, 1] >= wave_cutoff_list[cutoff_ind-1]) \\\n",
    "                                    & (co_refs_txt[:, 1] <= wave_cutoff_list[cutoff_ind]))[0]\n",
    "                line_absorb_emiss_match = cube_absorb_emiss[co_line_wave_mask, i, j]\n",
    "                vals, counts = np.unique(line_absorb_emiss_match, return_counts=True) #find number of unique elements of -1, 1, or 0 to determine bool\n",
    "                absorb_emiss_mode = vals[np.argmax(counts)] #count bools to determine mode\n",
    "\n",
    "                #now using the mode to pick and compute the correct baseline\n",
    "                if absorb_emiss_mode == 1: #emission, do old way\n",
    "                    baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]\n",
    "                    # baseline = baseline_fitter.asls(flux_1pix[cutoff_mask], lam=1e2, p=0.9)[0]\n",
    "                elif absorb_emiss_mode == -1: #absorption, change slightly\n",
    "                    baseline = baseline_fitter.pspline_asls(jwst_data[:,i,j][cutoff_mask], p=0.9, lam=1e1)[0]\n",
    "                    # baseline = baseline_fitter.noise_median(flux_1pix[cutoff_mask], half_window=2)[0] \n",
    "                else: #default to original if we can't figure anything else out...\n",
    "                    # baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]\n",
    "                    baseline = baseline_fitter.noise_median(jwst_data[:,i,j][cutoff_mask], half_window=2)[0] \n",
    "            baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "            #update counter for loop, do after everything else\n",
    "            cutoff_ind += 1\n",
    "\n",
    "\n",
    "        #if edge case at end, do it by hand\n",
    "        cutoff_mask = jwst_cube_wave > wave_cutoff_list[-1] #define mask past last marker\n",
    "        baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)     #compute baseline\n",
    "    \n",
    "        #given newly updated cutoffs, we compute the mode of the region to see if mostly absorption or emission\n",
    "        co_line_wave_mask = np.where((co_refs_txt[:, 1] >= wave_cutoff_list[-1]))[0]\n",
    "        line_absorb_emiss_match = cube_absorb_emiss[co_line_wave_mask, i, j]\n",
    "        vals, counts = np.unique(line_absorb_emiss_match, return_counts=True) #find number of unique elements of -1, 1, or 0 to determine bool\n",
    "        absorb_emiss_mode = vals[np.argmax(counts)] #count bools to determine mode\n",
    "        if absorb_emiss_mode != 1:\n",
    "            baseline = baseline_fitter.pspline_asls(bkg_top[cutoff_mask], lam=1e2, p=0.999, spline_degree=3)[0]\n",
    "        else:\n",
    "            baseline = baseline_fitter.pspline_asls(bkg_top[cutoff_mask], lam=1e3, p=0.1, spline_degree=2)[0]\n",
    "        baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "\n",
    "        # now trying to filter around our control or anchor points\n",
    "        N_res = 100. * 1e-3 #knowing that average spectral resolution for the instrument is about 1/1000 microns, then applying multiples of that\n",
    "        for cutoff_ind in range(len(wave_cutoff_list)):\n",
    "            idx = ( jwst_cube_wave >= (wave_cutoff_list[cutoff_ind]-N_res) ) & ( jwst_cube_wave <= (wave_cutoff_list[cutoff_ind]+N_res) ) #logical masks joined with * using N_res\n",
    "            idx_mask = np.where(idx)[0] #making mask\n",
    "            baseline_list[idx_mask] = savgol_filter(baseline_list[idx_mask], polyorder=1, window_length=5) #in region around mask, apply filters\n",
    "\n",
    "        #in case we want to do any last changes by hand, we can do them here...\n",
    "\n",
    "        # formulating a pseudo-continuum based on the baseline to determine ices and a transmission curve\n",
    "        baseline_fitter = Baseline(jwst_cube_wave, check_finite=False)\n",
    "        ice_list = baseline_fitter.pspline_asls(baseline_list, lam=1e2, p=0.9999, spline_degree=2)[0]\n",
    "\n",
    "        # for third to last case AFTER doing everything, we need to splice in a correction to follow the continuum better...\n",
    "        idx = (jwst_cube_wave >= wave_cutoff_list[len(wave_cutoff_list)-4]) & (jwst_cube_wave <= wave_cutoff_list[len(wave_cutoff_list)-1])\n",
    "        idx_mask = np.where(idx)[0] #making mask\n",
    "        baseline_fitter = Baseline(jwst_cube_wave[idx_mask], check_finite=False)\n",
    "        # baseline_list[idx_mask] = baseline_fitter.tophat(baseline_list[idx_mask], half_window=2)[0]\n",
    "        baseline_list[idx_mask] = baseline_fitter.pspline_asls(baseline_list[idx_mask], lam=3e1, p =0.1)[0]\n",
    "\n",
    "        #storing data into arrays!!!\n",
    "        baseline_fit_arr[:,i,j] = baseline_list \n",
    "        resid_arr[:,i,j] = jwst_data[:,i,j]  - baseline_list   \n",
    "        cont_arr[:,i,j] = baseline_fitter_global.pspline_asls(baseline_list, lam=1e2, p=0.9999, spline_degree=2)[0]  \n",
    "        ice_arr[:,i,j] = baseline_list - cont_arr[:,i,j] \n",
    "        transmission_arr[:,i,j] = 1.0 + ice_arr[:,i,j]/cont_arr[:,i,j]\n",
    "        tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])    \n",
    "    \n",
    "\n",
    "#tests to check shapes are correct\n",
    "# print('JWST: ', jwst_data.shape, ' Splined baseline Cube: ', baseline_fit_arr.shape, ' Summed baseline: ', baseline_sum_arr.shape,)\n",
    "#saving baseline as cube, not summed, with MJy/sr\n",
    "astropy_cube_units = u.MJy/u.sr #need to define units\n",
    "\n",
    "#saving baseline as cube, not summed, with MJy/sr\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=baseline_fit_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "# cube = cube.with_spectral_unit(u.um)\n",
    "cube_savepath = 'Baseline/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_tophat_jcbd.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline_subtracted cube, with MJy/sr\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "nocont_cube = SpectralCube(data=resid_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "# nocont_cube = cube.with_spectral_unit(u.um)\n",
    "nocont_cube_savepath = 'Baseline_Subtracted/'\n",
    "nocont_cube_name = protostar_id + '_NIRspec_cube_basefit_tophat_jcbd.fits'\n",
    "nocont_cube.write(nocont_cube_savepath+nocont_cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', nocont_cube_savepath+nocont_cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, with cgs units\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=cont_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Continuum/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_cont.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#ways to average baselines and also develope a header for relevant usage\n",
    "continuum_sum_arr = np.sum(cube_units* cont_arr, axis=0)\n",
    "continuum_med_arr = np.median(cube_units * cont_arr, axis=0)\n",
    "continuum_mean_arr = np.mean(cube_units * cont_arr, axis=0)\n",
    "continuum_header = jwst_cube.header #need to edit header a bit\n",
    "continuum_header['BUNIT'] = 'erg cm-2 s-1 sr-1' \n",
    "continuum_header['CUNIT3'] = 'um'\n",
    "continuum_header['HISTORY'] = 'The following steps apply: converted to cgs units (erg/s/cm^2/sr). Then baseline is averaged accordingly.'\n",
    "\n",
    "#saving summed cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_sum'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_sum_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#saving median cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_med'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_med_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#saving mean cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_mean'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_mean_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#given continuum, compute ices\n",
    "\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=ice_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_ice.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, could be with cgs units, but here is just a ratio...\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=transmission_arr, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_transmission.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, with cgs units\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=tau_ice_arr, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_icetau.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bfbd2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532839f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_28888\\1047518255.py:143: RuntimeWarning: invalid value encountered in true_divide\n",
      "  transmission_arr[:,i,j] = 1.0 + ice_arr[:,i,j]/cont_arr[:,i,j]\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_28888\\1047518255.py:144: RuntimeWarning: divide by zero encountered in log\n",
      "  tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])\n",
      "C:\\Users\\arubi\\AppData\\Local\\Temp\\ipykernel_28888\\1047518255.py:144: RuntimeWarning: invalid value encountered in log\n",
      "  tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:  Baseline/12_22_23_20126_update_NIRspec_cube_tophat_jcbd.fits\n",
      "Saved:  Baseline_Subtracted/12_22_23_20126_update_NIRspec_cube_basefit_tophat_jcbd.fits\n",
      "Saved:  Continuum/12_22_23_20126_update_NIRspec_cube_pspline_asls_cont.fits\n",
      "Saved:  Continuum/12_22_23_20126_update_NIRspec_Continuum_sum.fits\n",
      "Saved:  Continuum/12_22_23_20126_update_NIRspec_Continuum_med.fits\n",
      "Saved:  Continuum/12_22_23_20126_update_NIRspec_Continuum_mean.fits\n",
      "Saved:  Ices/12_22_23_20126_update_NIRspec_cube_pspline_asls_ice.fits\n",
      "Saved:  Ices/12_22_23_20126_update_NIRspec_cube_pspline_asls_transmission.fits\n",
      "Saved:  Ices/12_22_23_20126_update_NIRspec_cube_pspline_asls_icetau.fits\n"
     ]
    }
   ],
   "source": [
    "# Let's try making a baseline image while looping through wavelengths\n",
    "\n",
    "#params to smooth out data\n",
    "N_res = 100. * 1e-3 #knowing that average spectral resolution for the instrument is about 1/1000 microns, then applying multiples of that\n",
    "wave_cutoff_list = np.array([4.19, 4.32, 4.37, 4.4, 4.61, 4.695, 4.775, 4.84, 5.0]) # 4.939\n",
    "smooth_list = [1, 1, 10, 1, 5, 3, 15, 10, 2, 10] #smoothing parameters for baseline #third to last originally 3\n",
    "alpha_list = [1, 100, 50, 100, 3, 100, 0.1, 100, 7, 1] #regularization parameter (relative levels of noise and signal)\n",
    "\n",
    "#go through ONE file / protostar\n",
    "protostar_count = 4\n",
    "filepath = cube_file_list[protostar_count]\n",
    "\n",
    "#read in a cube that shows if each co line is in emission or absorption\n",
    "cube_absorb_emiss = fits.getdata(absorb_emiss_cube_list[protostar_count])\n",
    "co_refs_txt = np.genfromtxt(absorb_emiss_txt_list[protostar_count], delimiter=',', skip_header=1) # text file used to match indices to a given CO line\n",
    "\n",
    "#open and read a data file\n",
    "protostar_id = filepath.split('/')[0] # for reference later when saving files\n",
    "hdul = fits.open(filepath)\n",
    "jwst_cube = SpectralCube.read(hdul[1]) #accessing the cube for data  \n",
    "jwst_cube_wave = np.array(jwst_cube.spectral_axis.value, dtype=np.float64)[1:-1] #cut ends off data\n",
    "jwst_data = np.array(np.nan_to_num(jwst_cube._data), dtype=np.float64)[1:-1]\n",
    "err_cube = hdul['ERR'].data[1:-1]\n",
    "\n",
    "#figuring out units\n",
    "photometric_head = hdul[1].header\n",
    "delta_lambda = photometric_head['CDELT3'] #in microns ?\n",
    "pixel_area = photometric_head['PIXAR_SR'] # in sr\n",
    "'''\n",
    "pixel units for JWST are MJy/sr, the sr card is PIXAR_SR, ignore for now\n",
    "then MJy to cgs is 1e6*1 Jy/sr = 1e6 * 1e-23 erg/s/cm^2/spectral bandwidth in frequency, Hz per sr\n",
    "\n",
    "that is per frequency bandwidth! must multiply by it...\n",
    "since we only have the frequency band, we can convert by c = lam * nu, bandwidth=delta_nu = c/lam^2 * delta_lambda\n",
    "and then we must multiply by this bandwidth: have 1e6 * 1e-23 * c/lam^2 * delta_lambda * sr\n",
    "\n",
    "c units must change for what wavelength we use...here we use microns, so c in micron/sec is 3e8 m/s * (1e6 mic/m)\n",
    "so c = ~3e14\n",
    "\n",
    "and to prep in the loop, for each cube we will grab the delta_lambda and the pixel_area in sr\n",
    "'''\n",
    "cube_units = 1e6 * 1e-23 * 3e14/(jwst_cube_wave[:, None, None])**2. * pixel_area \n",
    "\n",
    "#set up arrays to be read in...\n",
    "baseline_fit_arr = np.zeros((jwst_data.shape)) #assume square, initialize as zeros\n",
    "resid_arr = np.zeros((jwst_data.shape)) #assume square, initialize as zeros\n",
    "cont_arr = np.zeros((jwst_data.shape))\n",
    "ice_arr = np.zeros((jwst_data.shape))\n",
    "transmission_arr = np.zeros((jwst_data.shape))\n",
    "tau_ice_arr = np.zeros((jwst_data.shape))\n",
    "\n",
    "#compute our fitted baseline of continuum+ices with a single baseline first with an initial tophat filter estimation\n",
    "# baseline_smoother = coeffs_list[-1][len(unres_wavelengths):len(unres_wavelengths)+len(smooth_list)]    \n",
    "baseline_fitter_global = Baseline(jwst_cube_wave, check_finite=True) #generic preset the baseline object given a list of x-values (wavelengths)\n",
    "#by explicit loops\n",
    "for i in range(jwst_data.shape[1]):\n",
    "    for j in range(jwst_data.shape[2]):\n",
    "        #access cube to separate out an initial estimate for the baseline\n",
    "        bkg_top = baseline_fitter_global.tophat(jwst_data[:,i,j], half_window=3)[0]\n",
    "\n",
    "        #begin to loop through different parameters, defining a new baseline for a given section of the spectrum\n",
    "        # baseline_alpha = stacked_coeffs[len(unres_wavelengths):, i, j] #need to gather our parameter, alpha\n",
    "        baseline_list = np.array([])\n",
    "\n",
    "        #formulating regimes to cutoff the spectrum and apply different smoothing factors\n",
    "        # cutoffs_flux_matched = bkg_top[[np.abs(wave - i).argmin() for i in wave_cutoff_list]]\n",
    "\n",
    "        #if edge case at start, do it by hand to omit conditionals\n",
    "        cutoff_mask = jwst_cube_wave < wave_cutoff_list[0] #define mask up to first marker\n",
    "        baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)     #compute baseline\n",
    "        baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[0],alpha=alpha_list[0])[0]\n",
    "        baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "        #if between two values and not at the edge cases, we loop..\n",
    "        cutoff_ind = 1 #to count loops\n",
    "        while cutoff_ind <= len(wave_cutoff_list)-1:\n",
    "            #take region of spectrum\n",
    "            idx = (jwst_cube_wave >= wave_cutoff_list[cutoff_ind-1]) & (jwst_cube_wave <= wave_cutoff_list[cutoff_ind]) #logical masks joined with * or & from PRIOR breakpoint\n",
    "            cutoff_mask = np.where(idx)[0] #determine mask between two values\n",
    "            baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)\n",
    "\n",
    "            #loop through many CO spectral lines to determine each individual baseline \n",
    "            if wave_cutoff_list[cutoff_ind] < 4.41: # len(co_line_wave_mask) == 0: #first check if we have to either by # of CO lines or wavelength itself\n",
    "                baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]\n",
    "            else:\n",
    "                #given newly updated cutoffs, we compute the mode of the region to see if mostly absorption or emission\n",
    "                co_line_wave_mask = np.where((co_refs_txt[:, 1] >= wave_cutoff_list[cutoff_ind-1]) \\\n",
    "                                    & (co_refs_txt[:, 1] <= wave_cutoff_list[cutoff_ind]))[0]\n",
    "                line_absorb_emiss_match = cube_absorb_emiss[co_line_wave_mask, i, j]\n",
    "                vals, counts = np.unique(line_absorb_emiss_match, return_counts=True) #find number of unique elements of -1, 1, or 0 to determine bool\n",
    "                absorb_emiss_mode = vals[np.argmax(counts)] #count bools to determine mode\n",
    "\n",
    "                #now using the mode to pick and compute the correct baseline\n",
    "                if absorb_emiss_mode == 1 and cutoff_ind != len(wave_cutoff_list) - 3: #emission, do old way\n",
    "                    baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]\n",
    "                    # baseline = baseline_fitter.asls(flux_1pix[cutoff_mask], lam=1e2, p=0.9)[0]\n",
    "                elif absorb_emiss_mode == 1 and cutoff_ind == len(wave_cutoff_list) - 3:\n",
    "                    # baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]            \n",
    "                    baseline = baseline_fitter.pspline_asls(bkg_top[cutoff_mask], p=0.045, lam=3e3)[0] \n",
    "                elif absorb_emiss_mode == -1: #absorption, change slightly\n",
    "                    baseline = baseline_fitter.pspline_asls(jwst_data[:,i,j][cutoff_mask], p=0.9, lam=1e1)[0]\n",
    "                    # baseline = baseline_fitter.noise_median(jwst_data[:,i,j][cutoff_mask], half_window=2)[0] \n",
    "                else: #default to original if we can't figure anything else out...\n",
    "                    # baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]\n",
    "                    baseline = baseline_fitter.noise_median(jwst_data[:,i,j][cutoff_mask], half_window=2)[0] \n",
    "            baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "            #update counter for loop, do after everything else\n",
    "            cutoff_ind += 1\n",
    "\n",
    "        #if edge case at end, do it by hand\n",
    "        cutoff_mask = jwst_cube_wave > wave_cutoff_list[-1] #define mask past last marker\n",
    "        baseline_fitter = Baseline(jwst_cube_wave[cutoff_mask], check_finite=False)     #compute baseline\n",
    "        # baseline = baseline_fitter.jbcd(bkg_top[cutoff_mask], half_window=smooth_list[cutoff_ind],alpha=alpha_list[cutoff_ind])[0]\n",
    "        baseline = baseline_fitter.pspline_asls(bkg_top[cutoff_mask], lam=1e2, p=0.999, spline_degree=3)[0]\n",
    "        baseline_list = np.concatenate((baseline_list, baseline)) #concat to list\n",
    "\n",
    "        # now trying to filter around our control or anchor points\n",
    "        N_res = 100. * 1e-3 #knowing that average spectral resolution for the instrument is about 1/1000 microns, then applying multiples of that\n",
    "        for cutoff_ind in range(len(wave_cutoff_list)):\n",
    "            idx = ( jwst_cube_wave >= (wave_cutoff_list[cutoff_ind]-N_res) ) & ( jwst_cube_wave <= (wave_cutoff_list[cutoff_ind]+N_res) ) #logical masks joined with * using N_res\n",
    "            idx_mask = np.where(idx)[0] #making mask\n",
    "            baseline_list[idx_mask] = savgol_filter(baseline_list[idx_mask], polyorder=1, window_length=5) #in region around mask, apply filters\n",
    "\n",
    "        #in case we want to do any last changes by hand, we can do them here...\n",
    "\n",
    "        # formulating a pseudo-continuum based on the baseline to determine ices and a transmission curve\n",
    "        baseline_fitter = Baseline(jwst_cube_wave, check_finite=False)\n",
    "        ice_list = baseline_fitter.pspline_asls(baseline_list, lam=1e2, p=0.9999, spline_degree=2)[0]\n",
    "\n",
    "        # for third to last case AFTER doing everything, we need to splice in a correction to follow the continuum better...\n",
    "        idx = (jwst_cube_wave >= wave_cutoff_list[len(wave_cutoff_list)-4]) & (jwst_cube_wave <= wave_cutoff_list[len(wave_cutoff_list)-1])\n",
    "        idx_mask = np.where(idx)[0] #making mask\n",
    "        baseline_fitter = Baseline(jwst_cube_wave[idx_mask], check_finite=False)\n",
    "        # baseline_list[idx_mask] = baseline_fitter.tophat(baseline_list[idx_mask], half_window=2)[0]\n",
    "        baseline_list[idx_mask] = baseline_fitter.pspline_asls(baseline_list[idx_mask], lam=3e1, p =0.1)[0]\n",
    "\n",
    "        #storing data into arrays!!!\n",
    "        baseline_fit_arr[:,i,j] = baseline_list \n",
    "        resid_arr[:,i,j] = jwst_data[:,i,j]  - baseline_list   \n",
    "        cont_arr[:,i,j] = baseline_fitter_global.pspline_asls(baseline_list, lam=1e2, p=0.9999, spline_degree=2)[0]  \n",
    "        ice_arr[:,i,j] = baseline_list - cont_arr[:,i,j] \n",
    "        transmission_arr[:,i,j] = 1.0 + ice_arr[:,i,j]/cont_arr[:,i,j]\n",
    "        tau_ice_arr[:,i,j] = -1.0 * np.log(transmission_arr[:,i,j])    \n",
    "    \n",
    "\n",
    "#tests to check shapes are correct\n",
    "# print('JWST: ', jwst_data.shape, ' Splined baseline Cube: ', baseline_fit_arr.shape, ' Summed baseline: ', baseline_sum_arr.shape,)\n",
    "#saving baseline as cube, not summed, with MJy/sr\n",
    "astropy_cube_units = u.MJy/u.sr #need to define units\n",
    "\n",
    "#saving baseline as cube, not summed, with MJy/sr\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=baseline_fit_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "# cube = cube.with_spectral_unit(u.um)\n",
    "cube_savepath = 'Baseline/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_tophat_jcbd.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline_subtracted cube, with MJy/sr\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "nocont_cube = SpectralCube(data=resid_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "# nocont_cube = cube.with_spectral_unit(u.um)\n",
    "nocont_cube_savepath = 'Baseline_Subtracted/'\n",
    "nocont_cube_name = protostar_id + '_NIRspec_cube_basefit_tophat_jcbd.fits'\n",
    "nocont_cube.write(nocont_cube_savepath+nocont_cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', nocont_cube_savepath+nocont_cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, with cgs units\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=cont_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Continuum/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_cont.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#ways to average baselines and also develope a header for relevant usage\n",
    "continuum_sum_arr = np.sum(cube_units* cont_arr, axis=0)\n",
    "continuum_med_arr = np.median(cube_units * cont_arr, axis=0)\n",
    "continuum_mean_arr = np.mean(cube_units * cont_arr, axis=0)\n",
    "continuum_header = jwst_cube.header #need to edit header a bit\n",
    "continuum_header['BUNIT'] = 'erg cm-2 s-1 sr-1' \n",
    "continuum_header['CUNIT3'] = 'um'\n",
    "continuum_header['HISTORY'] = 'The following steps apply: converted to cgs units (erg/s/cm^2/sr). Then baseline is averaged accordingly.'\n",
    "\n",
    "#saving summed cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_sum'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_sum_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#saving median cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_med'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_med_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#saving mean cube...need to note in name...\n",
    "savepath = 'Continuum/' #set folder\n",
    "name = protostar_id + '_NIRspec_Continuum_mean'+'.fits' #probably should edit this to id+linenameONLY+wavelength for future\n",
    "fits_path = fits_saver(continuum_mean_arr, continuum_header, name, savepath) #saving\n",
    "print('Saved: ', fits_path) #I use to confirm file has right path\n",
    "\n",
    "#given continuum, compute ices\n",
    "\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=ice_arr*astropy_cube_units, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_ice.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, could be with cgs units, but here is just a ratio...\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=transmission_arr, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_transmission.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)\n",
    "\n",
    "#saving baseline as cube, not summed, with cgs units\n",
    "# cube_unit_converted = np.multiply(cube_units, jwst_data)\n",
    "cube = SpectralCube(data=tau_ice_arr, wcs=jwst_cube.wcs)\n",
    "cube_savepath = 'Ices/'\n",
    "cube_name = protostar_id + '_NIRspec_cube_pspline_asls_icetau.fits'\n",
    "cube.write(cube_savepath+cube_name, format='fits', overwrite=True)\n",
    "print('Saved: ', cube_savepath+cube_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfeef98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68141940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.370000028051437e-06\n",
      "5.370000028051437e-06\n",
      "5.370000028051437e-06\n",
      "5.370000028051437e-06\n",
      "5.370000028051437e-06\n"
     ]
    }
   ],
   "source": [
    "#go through all files and note units for later...\n",
    "for protostar_count, filepath in enumerate(cube_file_list):\n",
    "    #open and read a data file\n",
    "    protostar_id = filepath.split('/')[0] # for reference later when saving files\n",
    "    hdul = fits.open(filepath)\n",
    "\n",
    "    #figuring out units\n",
    "    photometric_head = hdul[1].header\n",
    "    delta_lambda = photometric_head['CDELT3'] #in microns ?\n",
    "    pixel_area = photometric_head['PIXAR_SR'] # in sr\n",
    "\n",
    "    cube_units = 1e6 * 1e-23 * 3e14 * delta_lambda \n",
    "    print(cube_units) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80900259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' after creating file, add to the header\\n\\nfile: 1D spectrum by Adam Rubinstein\\nprotostar: IRAS 16253\\nstat method: sum\\naperture shape: square\\naperture side length or diameter: 1 arcsec\\nadditional notes: baseline fitted and subtracted using pybaselines tophat, then jbcd methods. \\nadditional notes: centered using alma coordinates\\n\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read in a 3-D IFU datacube of interest, and header\n",
    "#first, note the path\n",
    "protostar_folders = ['IRAS16253', 'B335', 'HOPS153', 'HOPS370', 'IRAS20126']\n",
    "protostar_ind = 4\n",
    "cube_file_list = [glob('Baseline_Subtracted/' + i + '*.fits')[0].replace('\\\\', '/') for i in protostar_folders] #change the wildcard '*' here!\n",
    "\n",
    "# Read in a 3-D IFU datacube of interest, and header\n",
    "#first, note the path\n",
    "cube_file = cube_file_list[protostar_ind]\n",
    "hdul = fits.open(cube_file)\n",
    "cube = fits.getdata(cube_file)\n",
    "nirspec_cube = SpectralCube.read(hdul[0]) #accessing the cube for data  \n",
    "header_cube = hdul[0].header\n",
    "\n",
    "# define the wavelength grid (microns) from the header\n",
    "# offset_list = [1.95e-3, 2e-3, 9.75e-4, 1.05e-3, 1.825e-3] #done by hand\n",
    "offset_list = [1.85e-3, 2e-3, 1.1e-3, 1.1e-3, 2.25e-3] #experimental round 2 with initial changes to baselines\n",
    "wave_offset = offset_list[protostar_ind] #unit = microns, alt value is 2e-4 microns, while cdelt is about E-9 m or E-3 mic...\n",
    "wave_factor = 1 #/1.001 #for wavelength calibrating\n",
    "wave_units = 1e6 #to convert from meters to microns\n",
    "wave = wave_factor * wave_units * nirspec_cube.spectral_axis.value + wave_offset\n",
    "\n",
    "# make a simple 1d spectrum of the central region, taking sum or median to attempt to account for cosmic rays\n",
    "# central_sources = [(48,45), (44,43), (47, 52), (41, 45), (46, 48)]\n",
    "# central_sources = [(48,46), (44,44), (44, 41), (41, 45), (38, 42)] #this one has fewer artifacts\n",
    "central_sources = [(int(46.57459417809592), int(45.12978229)),  (int(46.73250708463416), int(43.13112798)), (int(46.47088442936513), int(46.6279981)), \\\n",
    "                        (int(41.71119797770727), int(43.61467905)), (int(43.38667807448542), int(43.15705917))]\n",
    "\n",
    "arc_to_pix = 1 * 2.7777778191699e-05 * 3600.0\n",
    "center_widths = [int(1 / arc_to_pix)] * 5\n",
    "flux1 = np.sum(cube[:, central_sources[protostar_ind][0]-center_widths[protostar_ind]:central_sources[protostar_ind][1]+center_widths[protostar_ind],\\\n",
    "                       central_sources[protostar_ind][0]-center_widths[protostar_ind]:central_sources[protostar_ind][1]+center_widths[protostar_ind]], \\\n",
    "                        axis=(1,2)) #for an example of a single pixel\n",
    "# flux1 = cube[:, int(central_sources[protostar_ind][0]), int(central_sources[protostar_ind][1]) ].astype(np.float32) #for an example of a single pixel\n",
    "flux1 = np.nan_to_num(flux1)\n",
    "\n",
    "#plot sample spectrum\n",
    "plt.plot(wave, flux1)\n",
    "plt.xlabel('Wavelength (microns)')\n",
    "plt.ylabel('Intensity (MJy/sr)')\n",
    "\n",
    "#store spectra into dataframe and save it\n",
    "df_spectrum = pd.DataFrame({'Wavelength(mic)':wave, 'Flux(MJy/sr)':flux1})\n",
    "savepath = 'Spectra1D_tests/' + protostar_folders[protostar_ind] + '_baseFit_1dSpectrum.txt'\n",
    "df_spectrum.to_csv(savepath)\n",
    "\n",
    "''' after creating file, add to the header\n",
    "\n",
    "file: 1D spectrum by Adam Rubinstein\n",
    "protostar: IRAS 16253\n",
    "stat method: sum\n",
    "aperture shape: square\n",
    "aperture side length or diameter: 1 arcsec\n",
    "additional notes: baseline fitted and subtracted using pybaselines tophat, then jbcd methods. \n",
    "additional notes: centered using alma coordinates\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f4c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "76ea0b5a44b5f043d6c4635159a3bee32cd62df1b18398bac551d6d1b233642a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
